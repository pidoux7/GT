{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3309d60ce9652b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Importing Libraries ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:09.804975Z",
     "start_time": "2024-01-12T10:15:52.592032Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.6.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (1.26.2)\n",
      "Requirement already satisfied: boto3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (1.34.11)\n",
      "Requirement already satisfied: requests in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (4.47.0)\n",
      "Requirement already satisfied: regex in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2023.12.25)\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.11.2)\n",
      "Requirement already satisfied: fsspec in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.12.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.11 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (1.34.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.11->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.11->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sparse in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (1.26.2)\n",
      "Requirement already satisfied: scipy>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (1.11.4)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (0.58.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from numba>=0.49->sparse) (0.41.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torchmetrics in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (1.26.2)\n",
      "Requirement already satisfied: packaging>17.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (2.1.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2.11.2)\n",
      "Requirement already satisfied: fsspec in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install import_ipynb\n",
    "!pip install -U -q PyDrive\n",
    "!pip install pytorch_pretrained_bert\n",
    "!pip install sparse\n",
    "!pip install transformers\n",
    "!pip install torchmetrics\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fd4fd9552085c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:10.982020Z",
     "start_time": "2024-01-12T10:16:09.807173Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e0e82211314cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.323941Z",
     "start_time": "2024-01-12T10:16:10.985289Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as tgmnn\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataListLoader as GraphLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "import sklearn.metrics as skm\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import itertools\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import ast\n",
    "from typing import Optional, Tuple, Union\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e631e9d8d333ec2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Importing Data ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b39c3e0ba85e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.329435Z",
     "start_time": "2024-01-12T10:16:12.325377Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9404\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################################\n",
    "\n",
    "'''\n",
    "chemin = \"../Tests_donnees/\"\n",
    "\n",
    "# ouvrir un fichier pickle en mode lecture\n",
    "with open(chemin + \"dic_global_reverse.pkl\", \"rb\") as fichier:\n",
    "    mon_depickler = pickle.Unpickler(fichier)\n",
    "    dic = mon_depickler.load()\n",
    "    \n",
    "#print(dic.keys())\n",
    "\n",
    "nb_nodes = len(dic)+5\n",
    "print(nb_nodes)\n",
    "'''\n",
    "#######################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93aef5aba8cac70",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Defining classes ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4d4485cac2fe92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.341467Z",
     "start_time": "2024-01-12T10:16:12.338221Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### Transformer Conv ###############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class TransformerConv(MessagePassing):\n",
    "    _alpha: OptTensor\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        heads: int = 1,\n",
    "        concat: bool = True,\n",
    "        beta: bool = False,\n",
    "        dropout: float = 0.,\n",
    "        edge_dim: Optional[int] = None,\n",
    "        bias: bool = True,\n",
    "        root_weight: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.beta = beta and root_weight\n",
    "        self.root_weight = root_weight\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        self.edge_dim = edge_dim\n",
    "        self._alpha = None\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
    "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
    "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
    "        self.layernorm1 = LayerNorm(out_channels)\n",
    "        self.layernorm2 = LayerNorm(out_channels)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.proj = Linear(heads * out_channels, out_channels)\n",
    "        self.ffn = Linear(out_channels, out_channels)\n",
    "        self.ffn2 = Linear(out_channels, out_channels)\n",
    "        if edge_dim is not None:\n",
    "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
    "        else:\n",
    "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.lin_key.reset_parameters()\n",
    "        self.lin_query.reset_parameters()\n",
    "        self.lin_value.reset_parameters()\n",
    "        if self.edge_dim:\n",
    "            self.lin_edge.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor = None, batch=None, return_attention_weights=None):\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
    "        r\"\"\"Runs the forward pass of the module.\n",
    "\n",
    "        Args:\n",
    "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
    "                will additionally return the tuple\n",
    "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
    "                attention weights for each edge. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        H, C = self.heads, self.out_channels\n",
    "        residual = x\n",
    "        x = self.layernorm1(x, batch)\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "        query = self.lin_query(x[1]).view(-1, H, C)\n",
    "        key = self.lin_key(x[0]).view(-1, H, C)\n",
    "        value = self.lin_value(x[0]).view(-1, H, C)\n",
    "        # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa\n",
    "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
    "                             edge_attr=edge_attr, size=None)\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "        if self.concat:\n",
    "            out = self.proj(out.view(-1, self.heads * self.out_channels))\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out+residual\n",
    "        residual = out\n",
    "\n",
    "        out = self.layernorm2(out)\n",
    "        out = self.gelu(self.ffn(out))\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.ffn2(out)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out + residual\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            assert alpha is not None\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                return out, (edge_index, alpha)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                return out, edge_index.set_value(alpha, layout='coo')\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
    "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> Tensor:\n",
    "\n",
    "\n",
    "        if self.lin_edge is not None:\n",
    "            assert edge_attr is not None\n",
    "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,\n",
    "                                                      self.out_channels)\n",
    "            key_j = key_j + edge_attr\n",
    "\n",
    "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = value_j\n",
    "        if edge_attr is not None:\n",
    "            out = out + edge_attr\n",
    "\n",
    "        out = out * alpha.view(-1, self.heads, 1)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, heads={self.heads})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f416b0d45c5ca51c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.343284Z",
     "start_time": "2024-01-12T10:16:12.342155Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### Graph Transformer ###############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class GraphTransformer(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformerconv1 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv2 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv3 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=False)\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.hidden_size // 5) \n",
    "        self.embed_ee = nn.Embedding(8, config.hidden_size // 5)\n",
    "                    \n",
    "\n",
    "    def forward(self, x, edge_index, edge_index_readout, edge_attr, batch):\n",
    "        #print(\"GT\")\n",
    "        indices = (x==0).nonzero().squeeze()\n",
    "        h_nodes = self.transformerconv1(x=self.embed(x), edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv2(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv3(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        x = h_nodes[indices]\n",
    "        return x, h_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c6b6ff5ca752b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.358528Z",
     "start_time": "2024-01-12T10:16:12.344825Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "######################################################## Bert Config ##################################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.graph_dropout_prob = config.get('graph_dropout_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7c1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pre_training_1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Pre_training_1, self).__init__()\n",
    "        self.config = config\n",
    "        self.gnn = GraphTransformer(config)\n",
    "        self.linear = nn.Linear(self.config.hidden_size // 5, self.config.vocab_size)\n",
    "        self.layers = nn.ModuleList([self.gnn, self.linear])\n",
    "\n",
    "    def forward(self, nodes, edge_index, edge_index_readout, edge_attr, batch):\n",
    "        # Define the forward pass using self.gnn and self.linear as needed\n",
    "        vst,x = self.gnn(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e351bc79848c792a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.359575Z",
     "start_time": "2024-01-12T10:16:12.347625Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "############################################################ GDSet ####################################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class GDSet(Dataset):\n",
    "    def __init__(self, g):\n",
    "        self.g = g\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        g = self.g[index]\n",
    "        for i in range(len(g)):\n",
    "          g[i]['posi_ids'] = i\n",
    "        return g\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27382901bf1746",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Importing Data ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81192e04deabcfb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.548569Z",
     "start_time": "2024-01-12T10:16:12.350550Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../../data/data_pad.pkl', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db8d113daefd13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##################################################### Splitting Data ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd142a2914b09e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.331231Z",
     "start_time": "2024-01-12T10:16:12.329887Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr=1\n",
    "\n",
    "#######################################################################################################################################\n",
    "k = 5\n",
    "\n",
    "#######################################################################################################################################\n",
    "pourcentage_nodes_to_mask = 0.15\n",
    "labels_masked_nodes = []\n",
    "mask_node_embeddings = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1794e18e1eb60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.550870Z",
     "start_time": "2024-01-12T10:16:13.549092Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_l = int(len(dataset)*0.70)\n",
    "val_l = int(len(dataset)*0.10)\n",
    "test_l = len(dataset) - val_l - train_l\n",
    "number_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f332815fae943e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.554956Z",
     "start_time": "2024-01-12T10:16:13.552646Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=1, test_size=.20, random_state=rr)\n",
    "\n",
    "\n",
    "for i, (train_index_tmp, test_index) in enumerate(rs.split(dataset)):\n",
    "  rs2 = ShuffleSplit(n_splits=1, test_size=.125, random_state=rr)\n",
    "  for j, (train_index, val_index) in enumerate(rs2.split(train_index_tmp)):\n",
    "    train_index = train_index_tmp[train_index]\n",
    "\n",
    "    trainDSet = [dataset[x] for x in train_index]\n",
    "    valDSet = [dataset[x] for x in val_index]\n",
    "    testDSet = [dataset[x] for x in test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a004db21db04ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###################################################### Config Files ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2724e7a55d6dadc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.559805Z",
     "start_time": "2024-01-12T10:16:13.556335Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    'model_path': 'model/', # where to save model\n",
    "    'model_name': 'CVDTransformer', # model name\n",
    "    'file_name': 'log.txt',  # log path\n",
    "}\n",
    "#create_folder(file_config['model_path'])\n",
    "\n",
    "global_params = {\n",
    "    'max_seq_len': 50,\n",
    "    'month': 1,\n",
    "    'gradient_accumulation_steps': 1\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 0.001,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 5,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': \"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'data_len' : len(dataset),\n",
    "    'train_data_len' : train_l,\n",
    "    'val_data_len' : val_l,\n",
    "    'test_data_len' : test_l,\n",
    "    'epochs' : 50,\n",
    "    'action' : 'train'\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'vocab_size': 9405, # number of disease + symbols for word embedding (avec vst) + 1 for mask\n",
    "    'edge_relationship_size': 8, # number of vocab for edge_attr\n",
    "    'hidden_size': 50*5, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': 151, # number of vocab for age embedding\n",
    "    'time_vocab_size': 380, # number of vocab for time embedding\n",
    "    'type_vocab_size': 11, # number of vocab for type embedding\n",
    "    'node_attr_size': 8, # number of vocab for node_attr embedding\n",
    "    'gender_vocab_size': 2,\n",
    "    'ethnicity_vocab_size': 2,\n",
    "    'race_vocab_size': 6,\n",
    "    'num_labels':1,\n",
    "    'max_position_embedding': 50, # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.2, # dropout rate\n",
    "    'graph_dropout_prob': 0.2, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 2, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.2, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "    'number_output' : 1,\n",
    "    'n_layers' : 3 - 1,\n",
    "    'alpha' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4fe3f5c666bab2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "######################################################## CUDA ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c787c2405763db0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.560181Z",
     "start_time": "2024-01-12T10:16:13.558255Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n"
     ]
    }
   ],
   "source": [
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# print which device is used\n",
    "print('device: ', train_params['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc6d61c7c5ee83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Creating Model ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d55dfca883627",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.568976Z",
     "start_time": "2024-01-12T10:16:13.560797Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conf = BertConfig(model_config)\n",
    "model = Pre_training_1(conf).to(train_params['device'])\n",
    "vars = [i for i in model.parameters()]\n",
    "\n",
    "optim = torch.optim.AdamW(vars, lr=optim_param['lr'])\n",
    "CE_loss = torch.nn.CrossEntropyLoss(ignore_index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb286a7f3cab35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Training Functions ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "<class 'list'>\n",
      "torch.Size([9405])\n"
     ]
    }
   ],
   "source": [
    "print(len(vars))\n",
    "print(type(vars))\n",
    "print(vars[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f469dbb0caa05f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.585028Z",
     "start_time": "2024-01-12T10:16:13.569076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(trainload, device, config, ignore = False):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for step, data in tqdm(enumerate(trainload)):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        batched_data = Batch()\n",
    "        graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        nodes = graph_batch.x\n",
    "                \n",
    "        list_index = [i for i in range(nodes.shape[0])]\n",
    "        random.shuffle(list_index)\n",
    "        index_nodes_to_mask = list_index[:int((nodes.shape[0]) * pourcentage_nodes_to_mask)]\n",
    "        index_nodes_not_masked = list(set(list_index) - set(index_nodes_to_mask))\n",
    "        labels_nodes = nodes\n",
    "        ytrue = nodes\n",
    "        if ignore:\n",
    "            labels_nodes[index_nodes_not_masked] = 3\n",
    "        nodes[index_nodes_to_mask] = mask_node_embeddings\n",
    "        \n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_index_readout = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        batch = graph_batch.batch\n",
    "        attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "        attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "\n",
    "        pred = model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "\n",
    "        # couche lineaire pour predire les labels des noeuds masqués\n",
    "        \n",
    "        loss = CE_loss(pred, labels_nodes)\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        optim.step()\n",
    "\n",
    "        #sched.step()\n",
    "        del loss\n",
    "        #result = result + torch.sum(torch.sum(torch.mul(torch.abs(torch.subtract(pred, label)), target_mask), dim = 0)).cpu()\n",
    "        #sum_labels = sum_labels + torch.sum(target_mask, dim=0).cpu()\n",
    "    #print(result / sum_labels)\n",
    "    print(\"TOTAL TRAIN LOSS\", (tr_loss * train_params['batch_size']) / len(trainload))\n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost, pred,ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "98d4b3ccd3dccc1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.585636Z",
     "start_time": "2024-01-12T10:16:13.581468Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval(_valload, saving, device, config, ignore = False):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, data in tqdm(enumerate(_valload)):\n",
    "            optim.zero_grad()\n",
    "\n",
    "            batched_data = Batch()\n",
    "            graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            nodes = graph_batch.x\n",
    "                    \n",
    "            list_index = [i for i in range(nodes.shape[0])]\n",
    "            random.shuffle(list_index)\n",
    "            index_nodes_to_mask = list_index[:int((nodes.shape[0]) * pourcentage_nodes_to_mask)]\n",
    "            index_nodes_not_masked = list(set(list_index) - set(index_nodes_to_mask))\n",
    "            labels_nodes = nodes\n",
    "            ytrue = nodes\n",
    "            if ignore:\n",
    "                labels_nodes[index_nodes_not_masked] = 3\n",
    "            nodes[index_nodes_to_mask] = mask_node_embeddings\n",
    "            \n",
    "            edge_index = graph_batch.edge_index\n",
    "            edge_index_readout = graph_batch.edge_index\n",
    "            edge_attr = graph_batch.edge_attr\n",
    "            batch = graph_batch.batch\n",
    "            attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "            attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "\n",
    "            pred = model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "\n",
    "            # couche lineaire pour predire les labels des noeuds masqués\n",
    "\n",
    "            loss = CE_loss(pred, labels_nodes)\n",
    "            tr_loss += loss.item()\n",
    "            \n",
    "            del loss\n",
    "\n",
    "    print(\"TOTAL EVAL LOSS\", (tr_loss * train_params['batch_size']) / len(_valload))\n",
    "\n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost, pred, ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e74b020a899d96a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.585361Z",
     "start_time": "2024-01-12T10:16:13.576877Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(trainload, valload, device):\n",
    "    with open(\"v_behrt_log_train.txt\", 'w') as f:\n",
    "            f.write('')\n",
    "    best_val = math.inf\n",
    "    loss_train_liste = []\n",
    "    loss_val_liste = []\n",
    "    for e in tqdm(range(train_params[\"epochs\"])):\n",
    "        print(\"Epoch n\" + str(e))\n",
    "        train_loss, train_time_cost, pred_train, ytrue_train = train(trainload, device, config=model_config)\n",
    "        val_loss, val_time_cost, pred_eval, ytrue_eval = eval(valload, False, device, config=model_config)\n",
    "        accuracy_train = skm.accuracy_score(ytrue_train.cpu().detach().numpy(), pred_train.cpu().detach().numpy().argmax(axis=1))\n",
    "        accuracy_eval = skm.accuracy_score(ytrue_eval.cpu().detach().numpy(), pred_eval.cpu().detach().numpy().argmax(axis=1))\n",
    "\n",
    "        train_loss = (train_loss * train_params['batch_size']) / len(trainload)\n",
    "        val_loss = (val_loss * train_params['batch_size']) / len(valload)\n",
    "        loss_train_liste.append(train_loss)\n",
    "        loss_val_liste.append(val_loss)\n",
    "        print('TRAIN \\t{} secs'.format(train_time_cost))\n",
    "        print(f'TRAIN accuracy : {accuracy_train}')\n",
    "        with open(\"../../data/pre_training_1_log_train.txt\", 'a') as f:\n",
    "            f.write(\"Epoch n\" + str(e) + '\\n TRAIN {}\\t{} secs\\n'.format(train_loss, train_time_cost))\n",
    "            f.write('EVAL {}\\t{} secs\\n'.format(val_loss, val_time_cost) + '\\n\\n\\n')\n",
    "        print('EVAL \\t{} secs'.format(val_time_cost))\n",
    "        print('EVAL accuracy : {}\\n\\n'.format(accuracy_eval))\n",
    "        if val_loss < best_val:\n",
    "            print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "            torch.save(model.gnn.state_dict(), '../../data/'+'GraphTransformer_pretrain_1' + '.pch')\n",
    "            best_val = val_loss\n",
    "    epoch = [i for i in range(train_params[\"epochs\"])]\n",
    "    plt.plot(epoch, loss_train_liste)\n",
    "    plt.legend(['train'])\n",
    "    plt.plot(epoch,loss_val_liste)\n",
    "    plt.legend(['val'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('../../data/Pre_training_1.png')\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, val_loss, accuracy_train, accuracy_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedbac940be492c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "################################################### Evaluation Functions ####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25222bec6977e32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "######################################################## Saving #########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773a0f46fa4bbbc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##################################################### Training loop ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "daa43d6b90474890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:15.847059Z",
     "start_time": "2024-01-12T10:16:13.587010Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch n0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 4.110503793608427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.04it/s]\n",
      "  2%|▏         | 1/50 [01:06<54:28, 66.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.29940734867279123\n",
      "TRAIN \t61.53803730010986 secs\n",
      "TRAIN accuracy : 0.9829545454545454\n",
      "EVAL \t5.12227463722229 secs\n",
      "EVAL accuracy : 0.9860627177700348\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.3562289224265358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.79it/s]\n",
      "  4%|▍         | 2/50 [02:14<53:42, 67.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.12969074131470415\n",
      "TRAIN \t62.222342014312744 secs\n",
      "TRAIN accuracy : 0.9943181818181818\n",
      "EVAL \t5.175351142883301 secs\n",
      "EVAL accuracy : 0.9930313588850174\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:06, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.16576869583339565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 25.09it/s]\n",
      "  6%|▌         | 3/50 [03:25<54:08, 69.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.0904149576338132\n",
      "TRAIN \t66.55257987976074 secs\n",
      "TRAIN accuracy : 0.9943181818181818\n",
      "EVAL \t4.909373044967651 secs\n",
      "EVAL accuracy : 0.9941927990708479\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.10192274975880972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.87it/s]\n",
      "  8%|▊         | 4/50 [04:34<52:47, 68.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.06970071209297003\n",
      "TRAIN \t63.275622844696045 secs\n",
      "TRAIN accuracy : 0.9943181818181818\n",
      "EVAL \t5.159395456314087 secs\n",
      "EVAL accuracy : 0.9965156794425087\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0666289603068901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.62it/s]\n",
      " 10%|█         | 5/50 [05:42<51:31, 68.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.06402286369615379\n",
      "TRAIN \t63.36903786659241 secs\n",
      "TRAIN accuracy : 0.9943181818181818\n",
      "EVAL \t5.003401756286621 secs\n",
      "EVAL accuracy : 0.9965156794425087\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.04584231113409732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 25.18it/s]\n",
      " 12%|█▏        | 6/50 [06:50<50:05, 68.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.062411248298736254\n",
      "TRAIN \t62.621663093566895 secs\n",
      "TRAIN accuracy : 0.9943181818181818\n",
      "EVAL \t4.892164945602417 secs\n",
      "EVAL accuracy : 0.9988385598141696\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.034442542978208424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 21.95it/s]\n",
      " 14%|█▍        | 7/50 [07:59<49:06, 68.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05931900527985167\n",
      "TRAIN \t63.29973888397217 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.610600471496582 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:09, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.024611982705153697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 20.75it/s]\n",
      " 16%|█▌        | 8/50 [09:14<49:32, 70.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.06296911466784781\n",
      "TRAIN \t69.64620041847229 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.934920072555542 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:07, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.01835761915754331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.70it/s]\n",
      " 18%|█▊        | 9/50 [10:27<48:46, 71.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05730725137291893\n",
      "TRAIN \t67.63521599769592 secs\n",
      "TRAIN accuracy : 0.9943181818181818\n",
      "EVAL \t4.987590551376343 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.014143189853688808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.92it/s]\n",
      " 20%|██        | 10/50 [11:34<46:44, 70.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.056437270196137826\n",
      "TRAIN \t62.29473567008972 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.943136215209961 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.010951037064089444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.69it/s]\n",
      " 22%|██▏       | 11/50 [12:42<45:03, 69.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.06028265174210478\n",
      "TRAIN \t62.558815479278564 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.988528251647949 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.008893262439161635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 25.07it/s]\n",
      " 24%|██▍       | 12/50 [13:50<43:37, 68.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.058083100788754644\n",
      "TRAIN \t62.94296932220459 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.913257598876953 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:10, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.007029384734409976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.66it/s]\n",
      " 26%|██▌       | 13/50 [15:06<43:50, 71.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.061063268778842786\n",
      "TRAIN \t70.97821688652039 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.206210136413574 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:04, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.006113683834591811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.99it/s]\n",
      " 28%|██▊       | 14/50 [16:15<42:19, 70.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.06156545572004695\n",
      "TRAIN \t64.12649178504944 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.13383150100708 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.004753672224053424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.15it/s]\n",
      " 30%|███       | 15/50 [17:24<40:48, 69.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.061970704846668175\n",
      "TRAIN \t63.47498679161072 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.098595857620239 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0041931887642887074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.78it/s]\n",
      " 32%|███▏      | 16/50 [18:31<39:11, 69.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05975067199769207\n",
      "TRAIN \t62.147913694381714 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.178412437438965 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0035018915117714586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.45it/s]\n",
      " 34%|███▍      | 17/50 [19:37<37:35, 68.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.06201556022982852\n",
      "TRAIN \t61.38628315925598 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.036789178848267 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0033683101223321837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.73it/s]\n",
      " 36%|███▌      | 18/50 [20:44<36:14, 67.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.057011230731867396\n",
      "TRAIN \t62.04664969444275 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.979593515396118 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.002948260432675745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.81it/s]\n",
      " 38%|███▊      | 19/50 [21:52<35:05, 67.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05661588425528519\n",
      "TRAIN \t62.81345462799072 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.963712692260742 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.002552423384745913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.55it/s]\n",
      " 40%|████      | 20/50 [23:00<33:57, 67.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.056761691691449165\n",
      "TRAIN \t62.833051919937134 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.015593767166138 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.002448470657727782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.83it/s]\n",
      " 42%|████▏     | 21/50 [24:07<32:38, 67.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05785655764410424\n",
      "TRAIN \t61.447489976882935 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.16826605796814 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.001846807753772885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.44it/s]\n",
      " 44%|████▍     | 22/50 [25:14<31:26, 67.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.058301385326987996\n",
      "TRAIN \t62.005993604660034 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.038191080093384 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0017192477229171842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.14it/s]\n",
      " 46%|████▌     | 23/50 [26:21<30:19, 67.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.053339102869121906\n",
      "TRAIN \t62.22754192352295 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.100606203079224 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.001738956706920974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.68it/s]\n",
      " 48%|████▊     | 24/50 [27:29<29:12, 67.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05963741970463275\n",
      "TRAIN \t62.493074893951416 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.9902966022491455 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0015529743514848269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.51it/s]\n",
      " 50%|█████     | 25/50 [28:37<28:14, 67.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05973222039054531\n",
      "TRAIN \t63.566367387771606 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.0248613357543945 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0013750474856163038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.36it/s]\n",
      " 52%|█████▏    | 26/50 [29:45<27:02, 67.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05666421377620451\n",
      "TRAIN \t62.17823338508606 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.055874824523926 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.001289450151605757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.47it/s]\n",
      " 54%|█████▍    | 27/50 [30:51<25:46, 67.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05616558461576729\n",
      "TRAIN \t61.36854362487793 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.032581806182861 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0012717375341716717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.13it/s]\n",
      " 56%|█████▌    | 28/50 [31:59<24:42, 67.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.0584392406312128\n",
      "TRAIN \t62.574328899383545 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.1032867431640625 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0009500712067710569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 22.19it/s]\n",
      " 58%|█████▊    | 29/50 [33:08<23:45, 67.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.055742596564401704\n",
      "TRAIN \t63.403419971466064 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.550711154937744 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.001027992120521869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 25.04it/s]\n",
      " 60%|██████    | 30/50 [34:16<22:38, 67.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05499346302161202\n",
      "TRAIN \t63.07392716407776 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.918335437774658 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0008143017578343242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.26it/s]\n",
      " 62%|██████▏   | 31/50 [35:23<21:24, 67.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05310089162271864\n",
      "TRAIN \t61.75060176849365 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.076120853424072 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0009013587517249712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.57it/s]\n",
      " 64%|██████▍   | 32/50 [36:30<20:13, 67.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.053382051999543836\n",
      "TRAIN \t61.81974911689758 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.225281476974487 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0008845006936452432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.64it/s]\n",
      " 66%|██████▌   | 33/50 [37:38<19:09, 67.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05305295102477332\n",
      "TRAIN \t62.864394187927246 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.209970712661743 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:04, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0006220713593460919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.96it/s]\n",
      " 68%|██████▊   | 34/50 [38:47<18:10, 68.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05715916582861368\n",
      "TRAIN \t64.24705648422241 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.139719486236572 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0006603911930071794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.79it/s]\n",
      " 70%|███████   | 35/50 [39:55<17:00, 68.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.053900210914330005\n",
      "TRAIN \t62.44996428489685 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.176343679428101 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:04, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0006404563040467468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 22.46it/s]\n",
      " 72%|███████▏  | 36/50 [41:05<16:00, 68.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.054123286670746326\n",
      "TRAIN \t64.3985104560852 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.483633041381836 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0006647231840259028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.61it/s]\n",
      " 74%|███████▍  | 37/50 [42:13<14:51, 68.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05553197496698202\n",
      "TRAIN \t63.36125087738037 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.216249227523804 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.000572344571892499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.82it/s]\n",
      " 76%|███████▌  | 38/50 [43:20<13:37, 68.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05334858354137798\n",
      "TRAIN \t61.7860894203186 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.1694183349609375 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0006009671046444091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.39it/s]\n",
      " 78%|███████▊  | 39/50 [44:27<12:25, 67.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05265416480163296\n",
      "TRAIN \t61.79532194137573 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.049142360687256 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0004952394144981731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.74it/s]\n",
      " 80%|████████  | 40/50 [45:34<11:15, 67.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.051245039823326725\n",
      "TRAIN \t61.987708568573 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.187349081039429 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0004986480126647243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.91it/s]\n",
      " 82%|████████▏ | 41/50 [46:42<10:09, 67.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.051604759870906444\n",
      "TRAIN \t62.94887852668762 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.943086385726929 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0004319362489463639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.28it/s]\n",
      " 84%|████████▍ | 42/50 [47:51<09:02, 67.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.05144140487286881\n",
      "TRAIN \t62.96522498130798 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.290407657623291 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0003063619532648549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.83it/s]\n",
      " 86%|████████▌ | 43/50 [48:58<07:54, 67.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.050920549570267676\n",
      "TRAIN \t62.32279419898987 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.1671812534332275 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0006063894155059464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.90it/s]\n",
      " 88%|████████▊ | 44/50 [50:05<06:45, 67.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.051843171053910495\n",
      "TRAIN \t61.925840854644775 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.1530442237854 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.00035002459799665994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.40it/s]\n",
      " 90%|█████████ | 45/50 [51:12<05:35, 67.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.04611362999404804\n",
      "TRAIN \t61.25230574607849 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.048182487487793 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:01, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.000363942337690227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.31it/s]\n",
      " 92%|█████████▏| 46/50 [52:18<04:27, 66.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.0467670720309567\n",
      "TRAIN \t61.17625641822815 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.067035436630249 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:03, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.00037060744021762284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.63it/s]\n",
      " 94%|█████████▍| 47/50 [53:27<03:22, 67.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.051014257522212884\n",
      "TRAIN \t63.814680337905884 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.211724758148193 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.00045183635678760364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 23.81it/s]\n",
      " 96%|█████████▌| 48/50 [54:35<02:15, 67.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.04618906450961883\n",
      "TRAIN \t62.625951528549194 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.172678709030151 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.0003913467116614088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:05, 24.13it/s]\n",
      " 98%|█████████▊| 49/50 [55:42<01:07, 67.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.048949248883680054\n",
      "TRAIN \t62.58963918685913 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t5.102696180343628 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n",
      "Epoch n49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "859it [01:02, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 0.00030724444914028413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "123it [00:04, 24.82it/s]\n",
      "100%|██████████| 50/50 [56:50<00:00, 68.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 0.04830498974313387\n",
      "TRAIN \t62.868144273757935 secs\n",
      "TRAIN accuracy : 1.0\n",
      "EVAL \t4.960748910903931 secs\n",
      "EVAL accuracy : 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_params['max_len_seq'])\n",
    "if train_params['action'] == 'train' or train_params['action'] == 'resume':\n",
    "    trainload = GraphLoader(GDSet(trainDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "    valload = GraphLoader(GDSet(valDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "\n",
    "    train_loss, val_loss, accuracy_train, accuracy_eval = run_epoch(trainload, valload, train_params['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "023d8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour charger les parametre dans un nouveau modele:\n",
    "#new_gnn = GraphTransformer(conf)  # Créez une nouvelle instance de GraphTransformer\n",
    "#new_gnn.load_state_dict(torch.load('../../data/'+'GraphTransformer_pretrain_1' + '.pch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26ccf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
