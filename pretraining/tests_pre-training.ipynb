{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Importing Libraries ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb3309d60ce9652b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.1.3)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.6.2)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2.1.0)\r\n",
      "Requirement already satisfied: numpy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (1.26.2)\r\n",
      "Requirement already satisfied: boto3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (1.34.11)\r\n",
      "Requirement already satisfied: requests in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (4.47.0)\r\n",
      "Requirement already satisfied: regex in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2023.12.25)\r\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.11.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.12.2)\r\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.11 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (1.34.11)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (2023.11.17)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.11->boto3->pytorch_pretrained_bert) (2.8.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.0.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.11->boto3->pytorch_pretrained_bert) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: sparse in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.14.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (1.26.2)\r\n",
      "Requirement already satisfied: scipy>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (1.11.4)\r\n",
      "Requirement already satisfied: numba>=0.49 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (0.58.1)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from numba>=0.49->sparse) (0.41.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: transformers in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (4.36.2)\r\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.20.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (1.26.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.15.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (4.47.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: torchmetrics in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (1.2.1)\r\n",
      "Requirement already satisfied: numpy>1.20.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (1.26.2)\r\n",
      "Requirement already satisfied: packaging>17.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (23.2)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (2.1.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (0.10.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\r\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2.11.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2023.12.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.0.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "2.1.0\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install import_ipynb\n",
    "!pip install -U -q PyDrive\n",
    "!pip install pytorch_pretrained_bert\n",
    "!pip install sparse\n",
    "!pip install transformers\n",
    "!pip install torchmetrics\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:09.804975Z",
     "start_time": "2024-01-12T10:15:52.592032Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.7.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:10.982020Z",
     "start_time": "2024-01-12T10:16:09.807173Z"
    }
   },
   "id": "39fd4fd9552085c2",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_geometric/typing.py:63: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_scatter/_scatter_cpu.so, 0x0006): Symbol not found: __ZN5torch8autograd13_wrap_outputsERKNSt3__16vectorIN2at6TensorENS1_9allocatorIS4_EEEERKNS1_13unordered_setIPN3c1010TensorImplENS1_4hashISD_EENS1_8equal_toISD_EENS5_ISD_EEEESL_NSB_8ArrayRefINSB_8optionalIS4_EEEERKNS1_10shared_ptrINS0_4NodeEEENS1_8functionIFS7_S7_S7_EEE\n",
      "  Referenced from: <BEF9F452-9D77-323E-91B8-AF667F303838> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_scatter/_scatter_cpu.so\n",
      "  Expected in:     <66FB8649-BB87-3CD6-A177-462038DCAE02> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_geometric/typing.py:101: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_sparse/_spmm_cpu.so, 0x0006): Symbol not found: __ZN5torch8autograd13_wrap_outputsERKNSt3__16vectorIN2at6TensorENS1_9allocatorIS4_EEEERKNS1_13unordered_setIPN3c1010TensorImplENS1_4hashISD_EENS1_8equal_toISD_EENS5_ISD_EEEESL_NSB_8ArrayRefINSB_8optionalIS4_EEEERKNS1_10shared_ptrINS0_4NodeEEENS1_8functionIFS7_S7_S7_EEE\n",
      "  Referenced from: <4D05D979-F268-321D-A145-18B3BDA59213> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_sparse/_spmm_cpu.so\n",
      "  Expected in:     <66FB8649-BB87-3CD6-A177-462038DCAE02> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as tgmnn\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataListLoader as GraphLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "import sklearn.metrics as skm\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import itertools\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import ast\n",
    "from typing import Optional, Tuple, Union\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.323941Z",
     "start_time": "2024-01-12T10:16:10.985289Z"
    }
   },
   "id": "a6e0e82211314cd0",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Importing Data ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e631e9d8d333ec2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9400\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################################\n",
    "import pickle\n",
    "\n",
    "chemin = \"../Tests_donnees/\"\n",
    "\n",
    "# ouvrir un fichier pickle en mode lecture\n",
    "with open(chemin + \"dic_global_reverse.pkl\", \"rb\") as fichier:\n",
    "    mon_depickler = pickle.Unpickler(fichier)\n",
    "    dic = mon_depickler.load()\n",
    "    \n",
    "#print(dic.keys())\n",
    "\n",
    "nb_nodes = len(dic)+1\n",
    "print(nb_nodes)\n",
    "#######################################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.329435Z",
     "start_time": "2024-01-12T10:16:12.325377Z"
    }
   },
   "id": "a4b39c3e0ba85e77",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Global Variables ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d77e59a8825d6da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rr=1\n",
    "\n",
    "#######################################################################################################################################\n",
    "k = 5\n",
    "few_shots = 1\n",
    "\n",
    "#######################################################################################################################################\n",
    "pourcentage_nodes_to_mask = 0.15\n",
    "labels_masked_nodes = []\n",
    "mask_node_embeddings = 10000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.331231Z",
     "start_time": "2024-01-12T10:16:12.329887Z"
    }
   },
   "id": "36bd142a2914b09e",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Defining classes ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a93aef5aba8cac70"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### Transformer Conv ###############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class TransformerConv(MessagePassing):\n",
    "    _alpha: OptTensor\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        heads: int = 1,\n",
    "        concat: bool = True,\n",
    "        beta: bool = False,\n",
    "        dropout: float = 0.,\n",
    "        edge_dim: Optional[int] = None,\n",
    "        bias: bool = True,\n",
    "        root_weight: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.beta = beta and root_weight\n",
    "        self.root_weight = root_weight\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        self.edge_dim = edge_dim\n",
    "        self._alpha = None\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
    "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
    "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
    "        self.layernorm1 = LayerNorm(out_channels)\n",
    "        self.layernorm2 = LayerNorm(out_channels)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.proj = Linear(heads * out_channels, out_channels)\n",
    "        self.ffn = Linear(out_channels, out_channels)\n",
    "        self.ffn2 = Linear(out_channels, out_channels)\n",
    "        if edge_dim is not None:\n",
    "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
    "        else:\n",
    "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.lin_key.reset_parameters()\n",
    "        self.lin_query.reset_parameters()\n",
    "        self.lin_value.reset_parameters()\n",
    "        if self.edge_dim:\n",
    "            self.lin_edge.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor = None, batch=None, return_attention_weights=None):\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
    "        r\"\"\"Runs the forward pass of the module.\n",
    "\n",
    "        Args:\n",
    "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
    "                will additionally return the tuple\n",
    "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
    "                attention weights for each edge. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        H, C = self.heads, self.out_channels\n",
    "        residual = x\n",
    "        x = self.layernorm1(x, batch)\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "        query = self.lin_query(x[1]).view(-1, H, C)\n",
    "        key = self.lin_key(x[0]).view(-1, H, C)\n",
    "        value = self.lin_value(x[0]).view(-1, H, C)\n",
    "        # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa\n",
    "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
    "                             edge_attr=edge_attr, size=None)\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "        if self.concat:\n",
    "            out = self.proj(out.view(-1, self.heads * self.out_channels))\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out+residual\n",
    "        residual = out\n",
    "\n",
    "        out = self.layernorm2(out)\n",
    "        out = self.gelu(self.ffn(out))\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.ffn2(out)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out + residual\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            assert alpha is not None\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                return out, (edge_index, alpha)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                return out, edge_index.set_value(alpha, layout='coo')\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
    "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> Tensor:\n",
    "\n",
    "\n",
    "        if self.lin_edge is not None:\n",
    "            assert edge_attr is not None\n",
    "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,\n",
    "                                                      self.out_channels)\n",
    "            key_j = key_j + edge_attr\n",
    "\n",
    "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = value_j\n",
    "        if edge_attr is not None:\n",
    "            out = out + edge_attr\n",
    "\n",
    "        out = out * alpha.view(-1, self.heads, 1)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, heads={self.heads})')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.341467Z",
     "start_time": "2024-01-12T10:16:12.338221Z"
    }
   },
   "id": "4f4d4485cac2fe92",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### Graph Transformer ###############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class GraphTransformer(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformerconv1 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv2 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv3 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=False)\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.hidden_size // 5) \n",
    "        self.embed_ee = nn.Embedding(9+1, config.hidden_size // 5)\n",
    "                    \n",
    "\n",
    "    def forward(self, x, edge_index, edge_index_readout, edge_attr, batch):\n",
    "        #print(\"GT\")\n",
    "        indices = (x==0).nonzero().squeeze()\n",
    "        h_nodes = self.transformerconv1(x=self.embed(x), edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv2(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv3(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        x = h_nodes[indices]\n",
    "        return x, h_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.343284Z",
     "start_time": "2024-01-12T10:16:12.342155Z"
    }
   },
   "id": "f416b0d45c5ca51c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "######################################################## Bert Config ##################################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.graph_dropout_prob = config.get('graph_dropout_prob')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.358528Z",
     "start_time": "2024-01-12T10:16:12.344825Z"
    }
   },
   "id": "b2c6b6ff5ca752b7",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "############################################################ GDSet ####################################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class GDSet(Dataset):\n",
    "    def __init__(self, g):\n",
    "        self.g = g\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        g = self.g[index]\n",
    "        for i in range(len(g)):\n",
    "          g[i]['posi_ids'] = i\n",
    "        return g\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.g)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:12.359575Z",
     "start_time": "2024-01-12T10:16:12.347625Z"
    }
   },
   "id": "e351bc79848c792a",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Importing Data ######################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af27382901bf1746"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.548569Z",
     "start_time": "2024-01-12T10:16:12.350550Z"
    }
   },
   "id": "81192e04deabcfb9",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "##################################################### Splitting Data ######################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9db8d113daefd13"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_l = int(len(dataset)*0.70)\n",
    "val_l = int(len(dataset)*0.10)\n",
    "test_l = len(dataset) - val_l - train_l\n",
    "number_output = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.550870Z",
     "start_time": "2024-01-12T10:16:13.549092Z"
    }
   },
   "id": "e6e1794e18e1eb60",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=1, test_size=.20, random_state=rr)\n",
    "\n",
    "\n",
    "for i, (train_index_tmp, test_index) in enumerate(rs.split(dataset)):\n",
    "  rs2 = ShuffleSplit(n_splits=1, test_size=.125, random_state=rr)\n",
    "  for j, (train_index, val_index) in enumerate(rs2.split(train_index_tmp)):\n",
    "    train_index = train_index_tmp[train_index]\n",
    "    if few_shots < 1:\n",
    "      train_index = random.sample(list(train_index), int(len(train_index) * few_shots))\n",
    "    val_index = train_index_tmp[val_index]\n",
    "\n",
    "    trainDSet = [dataset[x] for x in train_index]\n",
    "    valDSet = [dataset[x] for x in val_index]\n",
    "    testDSet = [dataset[x] for x in test_index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.554956Z",
     "start_time": "2024-01-12T10:16:13.552646Z"
    }
   },
   "id": "11f332815fae943e",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "###################################################### Config Files ######################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55a004db21db04ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "file_config = {\n",
    "    'model_path': 'model/', # where to save model\n",
    "    'model_name': 'CVDTransformer', # model name\n",
    "    'file_name': 'log.txt',  # log path\n",
    "}\n",
    "#create_folder(file_config['model_path'])\n",
    "\n",
    "global_params = {\n",
    "    'max_seq_len': 50,\n",
    "    'month': 1,\n",
    "    'gradient_accumulation_steps': 1\n",
    "}\n",
    "\n",
    "optim_param = {\n",
    "    'lr': 3e-5,\n",
    "    'warmup_proportion': 0.1,\n",
    "    'weight_decay': 0.01\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': 5,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': global_params['max_seq_len'],\n",
    "    'device': \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    'data_len' : len(dataset),\n",
    "    'train_data_len' : train_l,\n",
    "    'val_data_len' : val_l,\n",
    "    'test_data_len' : test_l,\n",
    "    'epochs' : 5,\n",
    "    'action' : 'train'\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'vocab_size': 10000 + 1, # number of disease + symbols for word embedding (avec vst) + 1 for mask\n",
    "    'edge_relationship_size': 9, # number of vocab for edge_attr\n",
    "    'hidden_size': 50*5, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': 103, # number of vocab for age embedding\n",
    "    'gender_vocab_size': 2,\n",
    "    'ethnicity_vocab_size': 2,\n",
    "    'race_vocab_size': 6,\n",
    "    'num_labels':1,\n",
    "    'max_position_embedding': 50, # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.2, # dropout rate\n",
    "    'graph_dropout_prob': 0.2, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 2, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.2, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "    'number_output' : 1,\n",
    "    'n_layers' : 3 - 1,\n",
    "    'alpha' : 0.1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.559805Z",
     "start_time": "2024-01-12T10:16:13.556335Z"
    }
   },
   "id": "c2724e7a55d6dadc",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "######################################################## CUDA ##########################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d4fe3f5c666bab2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.560181Z",
     "start_time": "2024-01-12T10:16:13.558255Z"
    }
   },
   "id": "1c787c2405763db0",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Creating Model ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcdc6d61c7c5ee83"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conf = BertConfig(model_config)\n",
    "model = GraphTransformer(conf)\n",
    "\n",
    "vars = [i for i in model.parameters()]\n",
    "\n",
    "optim = torch.optim.AdamW(vars, lr=3e-5)\n",
    "CE_loss = torch.nn.CrossEntropyLoss(ignore_index=10000) # IGNORE LES MASKS DANS LA LOSS\n",
    "####### IGNORE INDEX ATTENTION PAS SUR DU FIX, SI CA APPREND PAS C'EST SUREMENT POUR CA #############"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.568976Z",
     "start_time": "2024-01-12T10:16:13.560797Z"
    }
   },
   "id": "b76d55dfca883627",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Training Functions ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb286a7f3cab35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_epoch(e, trainload, device, config):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for step, data in enumerate(trainload):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        batched_data = Batch()\n",
    "        graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        nodes = graph_batch.x\n",
    "        \n",
    "        ###############################################################################################################################\n",
    "        \n",
    "        list_index = [i for i in range(nodes.shape[0])]\n",
    "        random.shuffle(list_index)\n",
    "        index_nodes_to_mask = list_index[:int((nodes.shape[0]) * pourcentage_nodes_to_mask)]\n",
    "        # index_nodes_to_mask = [random.randint(0, nodes.shape[0]) for _ in range(int((nodes.shape[0]) * pourcentage_nodes_to_mask))] \n",
    "        labels_nodes = nodes\n",
    "        nodes[index_nodes_to_mask] = mask_node_embeddings\n",
    "        \n",
    "        #############################################################################################################################\n",
    "        \n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_index_readout = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        batch = graph_batch.batch\n",
    "        age_ids = torch.reshape(graph_batch.age, [graph_batch.age.shape[0] // 50, 50])\n",
    "        time_ids = torch.reshape(graph_batch.time, [graph_batch.time.shape[0] // 50, 50])\n",
    "        type_ids = torch.reshape(graph_batch.type, [graph_batch.type.shape[0] // 50, 50])\n",
    "        posi_ids = torch.reshape(graph_batch.posi_ids, [graph_batch.posi_ids.shape[0] // 50, 50])\n",
    "        attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "        attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "\n",
    "        labels = torch.reshape(graph_batch.label, [graph_batch.label.shape[0] // 50, 50])[:, 0].float()\n",
    "        masks = torch.reshape(graph_batch.mask, [graph_batch.mask.shape[0] // 50, 50])[:, 0]\n",
    "        x, h_nodes = model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "        print('h_nodes shape: ', h_nodes.shape)\n",
    "\n",
    "        \n",
    "        #############################################################################################################################\n",
    "        # couche lineaire pour predire les labels des noeuds masquÃ©s\n",
    "        print('nb nodes: ', nb_nodes)\n",
    "        linear = nn.Linear(config['hidden_size'] // 5, nb_nodes)\n",
    "        \n",
    "        pred = linear(h_nodes)\n",
    "        \n",
    "        print('pred shape: ', pred.shape)\n",
    "        print('labels nodes shape: ', labels_nodes.shape)\n",
    "        print('batch shape: ', batch.shape)\n",
    "        print('batch target shape: ', batch[labels_nodes == mask_node_embeddings].shape)\n",
    "        #############################################################################################################################\n",
    "\n",
    "        loss = CE_loss(pred, labels_nodes)\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        if step%500 == 0:\n",
    "            print(loss.item())\n",
    "        optim.step()\n",
    "        #sched.step()\n",
    "        del loss\n",
    "        #result = result + torch.sum(torch.sum(torch.mul(torch.abs(torch.subtract(pred, label)), target_mask), dim = 0)).cpu()\n",
    "        #sum_labels = sum_labels + torch.sum(target_mask, dim=0).cpu()\n",
    "    #print(result / sum_labels)\n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.585028Z",
     "start_time": "2024-01-12T10:16:13.569076Z"
    }
   },
   "id": "f469dbb0caa05f8e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(trainload, valload, device):\n",
    "    with open(\"v_behrt_log_train.txt\", 'w') as f:\n",
    "            f.write('')\n",
    "    best_val = math.inf\n",
    "    for e in range(train_params[\"epochs\"]):\n",
    "        print(\"Epoch n\" + str(e))\n",
    "        train_loss, train_time_cost = run_epoch(e, trainload, device, config=model_config)\n",
    "        val_loss, val_time_cost,pred, label, mask = eval(valload, False, device)\n",
    "        train_loss = (train_loss * train_params['batch_size']) / len(trainload)\n",
    "        val_loss = (val_loss * train_params['batch_size']) / len(valload)\n",
    "        print('TRAIN {}\\t{} secs\\n'.format(train_loss, train_time_cost))\n",
    "        with open(\"v_behrt_log_train.txt\", 'a') as f:\n",
    "            f.write(\"Epoch n\" + str(e) + '\\n TRAIN {}\\t{} secs\\n'.format(train_loss, train_time_cost))\n",
    "            f.write('EVAL {}\\t{} secs\\n'.format(val_loss, val_time_cost) + '\\n\\n\\n')\n",
    "        print('EVAL {}\\t{} secs\\n'.format(val_loss, val_time_cost))\n",
    "        if val_loss < best_val:\n",
    "            print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            #save_model(model_to_save.state_dict(), 'v_behrt')\n",
    "            best_val = val_loss\n",
    "    return train_loss, val_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.585361Z",
     "start_time": "2024-01-12T10:16:13.576877Z"
    }
   },
   "id": "e74b020a899d96a8",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "################################################### Evaluation Functions ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fedbac940be492c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval(_valload, saving, device):\n",
    "    tr_loss = 0\n",
    "    tr_g_loss = 0\n",
    "    tr_d_un = 0\n",
    "    tr_d_sup = 0\n",
    "    temp_loss = 0\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    if saving:\n",
    "        with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_preds.csv\", 'w') as f:\n",
    "            f.write('')\n",
    "        with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_labels.csv\", 'w') as f:\n",
    "            f.write('')\n",
    "        with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_masks.csv\", 'w') as f:\n",
    "            f.write('')\n",
    "    for step, data in enumerate(_valload):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        batched_data = Batch()\n",
    "        graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        nodes = graph_batch.x\n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_index_readout = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        batch = graph_batch.batch\n",
    "        age_ids = torch.reshape(graph_batch.age, [graph_batch.age.shape[0] // 50, 50])\n",
    "        time_ids = torch.reshape(graph_batch.time, [graph_batch.time.shape[0] // 50, 50])\n",
    "        type_ids = torch.reshape(graph_batch.type, [graph_batch.type.shape[0] // 50, 50])\n",
    "        posi_ids = torch.reshape(graph_batch.posi_ids, [graph_batch.posi_ids.shape[0] // 50, 50])\n",
    "        attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "        attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "\n",
    "        labels = torch.reshape(graph_batch.label, [graph_batch.label.shape[0] // 50, 50])[:, 0].float()\n",
    "        masks = torch.reshape(graph_batch.mask, [graph_batch.mask.shape[0] // 50, 50])[:, 0]\n",
    "        x, h_nodes = model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "\n",
    "        # if saving:\n",
    "        #     with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_preds.csv\", 'a') as f:\n",
    "        #         pd.DataFrame(logits.detach().cpu().numpy()).to_csv(f, header=False)\n",
    "        #     with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_labels.csv\", 'a') as f:\n",
    "        #         pd.DataFrame(labels.detach().cpu().numpy()).to_csv(f, header=False)\n",
    "        #     with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_masks.csv\", 'a') as f:\n",
    "        #         pd.DataFrame(masks.detach().cpu().numpy()).to_csv(f, header=False)\n",
    "        \n",
    "        loss = CE_loss(x, labels)\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        del loss\n",
    "\n",
    "    print(\"TOTAL LOSS\", (tr_loss * train_params['batch_size']) / len(_valload))\n",
    "\n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost, labels, masks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.585636Z",
     "start_time": "2024-01-12T10:16:13.581468Z"
    }
   },
   "id": "98d4b3ccd3dccc1f",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "######################################################## Saving #########################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d25222bec6977e32"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "' def save_model(_model_dict, file_name):\\n    torch.save(_model_dict, file_name) '"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def save_model(_model_dict, file_name):\n",
    "    torch.save(_model_dict, file_name) \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:13.587434Z",
     "start_time": "2024-01-12T10:16:13.584460Z"
    }
   },
   "id": "3568d456be3c49e8",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "##################################################### Training loop ######################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4773a0f46fa4bbbc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Epoch n0\n",
      "h_nodes shape:  torch.Size([3113, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([3113, 9400])\n",
      "labels nodes shape:  torch.Size([3113])\n",
      "batch shape:  torch.Size([3113])\n",
      "batch target shape:  torch.Size([466])\n",
      "9.253549575805664\n",
      "h_nodes shape:  torch.Size([1820, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([1820, 9400])\n",
      "labels nodes shape:  torch.Size([1820])\n",
      "batch shape:  torch.Size([1820])\n",
      "batch target shape:  torch.Size([273])\n",
      "h_nodes shape:  torch.Size([2215, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([2215, 9400])\n",
      "labels nodes shape:  torch.Size([2215])\n",
      "batch shape:  torch.Size([2215])\n",
      "batch target shape:  torch.Size([332])\n",
      "h_nodes shape:  torch.Size([3175, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([3175, 9400])\n",
      "labels nodes shape:  torch.Size([3175])\n",
      "batch shape:  torch.Size([3175])\n",
      "batch target shape:  torch.Size([476])\n",
      "h_nodes shape:  torch.Size([2597, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([2597, 9400])\n",
      "labels nodes shape:  torch.Size([2597])\n",
      "batch shape:  torch.Size([2597])\n",
      "batch target shape:  torch.Size([389])\n",
      "h_nodes shape:  torch.Size([3045, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([3045, 9400])\n",
      "labels nodes shape:  torch.Size([3045])\n",
      "batch shape:  torch.Size([3045])\n",
      "batch target shape:  torch.Size([456])\n",
      "h_nodes shape:  torch.Size([3112, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([3112, 9400])\n",
      "labels nodes shape:  torch.Size([3112])\n",
      "batch shape:  torch.Size([3112])\n",
      "batch target shape:  torch.Size([466])\n",
      "h_nodes shape:  torch.Size([2192, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([2192, 9400])\n",
      "labels nodes shape:  torch.Size([2192])\n",
      "batch shape:  torch.Size([2192])\n",
      "batch target shape:  torch.Size([328])\n",
      "h_nodes shape:  torch.Size([3076, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([3076, 9400])\n",
      "labels nodes shape:  torch.Size([3076])\n",
      "batch shape:  torch.Size([3076])\n",
      "batch target shape:  torch.Size([461])\n",
      "h_nodes shape:  torch.Size([1842, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([1842, 9400])\n",
      "labels nodes shape:  torch.Size([1842])\n",
      "batch shape:  torch.Size([1842])\n",
      "batch target shape:  torch.Size([276])\n",
      "h_nodes shape:  torch.Size([1829, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([1829, 9400])\n",
      "labels nodes shape:  torch.Size([1829])\n",
      "batch shape:  torch.Size([1829])\n",
      "batch target shape:  torch.Size([274])\n",
      "h_nodes shape:  torch.Size([2821, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([2821, 9400])\n",
      "labels nodes shape:  torch.Size([2821])\n",
      "batch shape:  torch.Size([2821])\n",
      "batch target shape:  torch.Size([423])\n",
      "h_nodes shape:  torch.Size([2435, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([2435, 9400])\n",
      "labels nodes shape:  torch.Size([2435])\n",
      "batch shape:  torch.Size([2435])\n",
      "batch target shape:  torch.Size([365])\n",
      "h_nodes shape:  torch.Size([1727, 50])\n",
      "nb nodes:  9400\n",
      "pred shape:  torch.Size([1727, 9400])\n",
      "labels nodes shape:  torch.Size([1727])\n",
      "batch shape:  torch.Size([1727])\n",
      "batch target shape:  torch.Size([259])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (250) to match target batch_size (5).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m trainload \u001B[38;5;241m=\u001B[39m GraphLoader(GDSet(trainDSet), batch_size\u001B[38;5;241m=\u001B[39mtrain_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m], shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      4\u001B[0m valload \u001B[38;5;241m=\u001B[39m GraphLoader(GDSet(valDSet), batch_size\u001B[38;5;241m=\u001B[39mtrain_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m], shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m----> 6\u001B[0m train_loss, val_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 8\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(trainload, valload, device)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch n\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e))\n\u001B[1;32m      7\u001B[0m train_loss, train_time_cost \u001B[38;5;241m=\u001B[39m run_epoch(e, trainload, device, config\u001B[38;5;241m=\u001B[39mmodel_config)\n\u001B[0;32m----> 8\u001B[0m val_loss, val_time_cost,pred, label, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43meval\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m (train_loss \u001B[38;5;241m*\u001B[39m train_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(trainload)\n\u001B[1;32m     10\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m (val_loss \u001B[38;5;241m*\u001B[39m train_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(valload)\n",
      "Cell \u001B[0;32mIn[18], line 46\u001B[0m, in \u001B[0;36meval\u001B[0;34m(_valload, saving, device)\u001B[0m\n\u001B[1;32m     36\u001B[0m x, h_nodes \u001B[38;5;241m=\u001B[39m model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# if saving:\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m#     with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_preds.csv\", 'a') as f:\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m#         pd.DataFrame(logits.detach().cpu().numpy()).to_csv(f, header=False)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m#     with open(\"/content/drive/My Drive/GANBEHRT/preds/v_behrt_masks.csv\", 'a') as f:\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m#         pd.DataFrame(masks.detach().cpu().numpy()).to_csv(f, header=False)\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mCE_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m tr_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m loss\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/loss.py:1179\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1180\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1181\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/functional.py:3053\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3051\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3052\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3053\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Expected input batch_size (250) to match target batch_size (5)."
     ]
    }
   ],
   "source": [
    "print(train_params['max_len_seq'])\n",
    "if train_params['action'] == 'train' or train_params['action'] == 'resume':\n",
    "    trainload = GraphLoader(GDSet(trainDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "    valload = GraphLoader(GDSet(valDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "\n",
    "    train_loss, val_loss = train(trainload, valload, train_params['device'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T10:16:15.847059Z",
     "start_time": "2024-01-12T10:16:13.587010Z"
    }
   },
   "id": "daa43d6b90474890",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
