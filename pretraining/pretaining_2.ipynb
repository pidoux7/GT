{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:52:43.107570Z",
     "start_time": "2024-01-11T15:52:40.996704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as tgmnn\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataListLoader as GraphLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "import sklearn.metrics as skm\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import itertools\n",
    "from einops import rearrange, repeat\n",
    "import ast\n",
    "from typing import Optional, Tuple, Union\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import pickle\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import transformers\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:07:59.772788Z",
     "start_time": "2024-01-11T16:07:59.740421Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TransformerConv(MessagePassing):\n",
    "    _alpha: OptTensor\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        heads: int = 1,\n",
    "        concat: bool = True,\n",
    "        beta: bool = False,\n",
    "        dropout: float = 0.,\n",
    "        edge_dim: Optional[int] = None,\n",
    "        bias: bool = True,\n",
    "        root_weight: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.beta = beta and root_weight\n",
    "        self.root_weight = root_weight\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        self.edge_dim = edge_dim\n",
    "        self._alpha = None\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
    "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
    "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
    "        self.layernorm1 = LayerNorm(out_channels)\n",
    "        self.layernorm2 = LayerNorm(out_channels)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.proj = Linear(heads * out_channels, out_channels)\n",
    "        self.ffn = Linear(out_channels, out_channels)\n",
    "        self.ffn2 = Linear(out_channels, out_channels)\n",
    "        if edge_dim is not None:\n",
    "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
    "        else:\n",
    "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.lin_key.reset_parameters()\n",
    "        self.lin_query.reset_parameters()\n",
    "        self.lin_value.reset_parameters()\n",
    "        if self.edge_dim:\n",
    "            self.lin_edge.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor = None, batch=None, return_attention_weights=None):\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
    "        r\"\"\"Runs the forward pass of the module.\n",
    "\n",
    "        Args:\n",
    "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
    "                will additionally return the tuple\n",
    "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
    "                attention weights for each edge. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        H, C = self.heads, self.out_channels\n",
    "        residual = x\n",
    "        x = self.layernorm1(x, batch)\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "        query = self.lin_query(x[1]).view(-1, H, C)\n",
    "        key = self.lin_key(x[0]).view(-1, H, C)\n",
    "        value = self.lin_value(x[0]).view(-1, H, C)\n",
    "        # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa\n",
    "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
    "                             edge_attr=edge_attr, size=None)\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "        if self.concat:\n",
    "            out = self.proj(out.view(-1, self.heads * self.out_channels))\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out+residual\n",
    "        residual = out\n",
    "\n",
    "        out = self.layernorm2(out)\n",
    "        out = self.gelu(self.ffn(out))\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.ffn2(out)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out + residual\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            assert alpha is not None\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                return out, (edge_index, alpha)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                return out, edge_index.set_value(alpha, layout='coo')\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
    "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> Tensor:\n",
    "\n",
    "\n",
    "        if self.lin_edge is not None:\n",
    "            assert edge_attr is not None\n",
    "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,\n",
    "                                                      self.out_channels)\n",
    "            key_j = key_j + edge_attr\n",
    "\n",
    "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = value_j\n",
    "        if edge_attr is not None:\n",
    "            out = out + edge_attr\n",
    "\n",
    "        out = out * alpha.view(-1, self.heads, 1)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, heads={self.heads})')\n",
    "\n",
    "\n",
    "class GraphTransformer(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformerconv1 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv2 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv3 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=False)\n",
    "\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.hidden_size // 5)\n",
    "        self.embed_ee = nn.Embedding(config.node_attr_size, config.hidden_size // 5)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        indices = (x==0).nonzero().squeeze()\n",
    "        h_nodes = self.transformerconv1(x=self.embed(x), edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv2(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv3(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        x = h_nodes[indices]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class BertEmbeddings(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, segment, age\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        #self.word_embeddings = nn.Linear(config.vocab_size, config.hidden_size)\n",
    "        self.word_embeddings = GraphTransformer(config)\n",
    "        self.type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size//5)\n",
    "        self.age_embeddings = nn.Embedding(config.age_vocab_size, config.hidden_size//5). \\\n",
    "            from_pretrained(embeddings=self._init_posi_embedding(config.age_vocab_size, config.hidden_size//5))\n",
    "        self.time_embeddings = nn.Embedding(config.time_vocab_size , config.hidden_size//5). \\\n",
    "            from_pretrained(embeddings=self._init_posi_embedding(config.time_vocab_size, config.hidden_size//5))\n",
    "        self.posi_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size//5). \\\n",
    "            from_pretrained(embeddings=self._init_posi_embedding(config.max_position_embeddings, config.hidden_size//5))\n",
    "\n",
    "\n",
    "        self.seq_layers = nn.Sequential(\n",
    "            nn.LayerNorm(config.hidden_size),\n",
    "            nn.Dropout(config.hidden_dropout_prob),\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size)\n",
    "        self.acti = nn.GELU()\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, config.hidden_size))\n",
    "\n",
    "    def forward(self, nodes, edge_index,  edge_attr, batch, age_ids, time_ids,  type_ids, posi_ids):\n",
    "        word_embed = self.word_embeddings(nodes, edge_index, edge_attr, batch)\n",
    "        type_embeddings = self.type_embeddings(type_ids)\n",
    "        age_embed = self.age_embeddings(age_ids)\n",
    "        time_embeddings = self.time_embeddings(time_ids)\n",
    "        posi_embeddings = self.posi_embeddings(posi_ids)\n",
    "\n",
    "        word_embed = torch.reshape(word_embed, type_embeddings.shape)\n",
    "        embeddings = torch.cat((word_embed, type_embeddings, posi_embeddings, age_embed, time_embeddings), dim=2)\n",
    "        \n",
    "        b, n, _ = embeddings.shape\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        embeddings = torch.cat((cls_tokens, embeddings), dim=1)\n",
    "        embeddings = self.seq_layers(embeddings)\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    def _init_posi_embedding(self, max_position_embedding, hidden_size):\n",
    "        def even_code(pos, idx):\n",
    "            return np.sin(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        def odd_code(pos, idx):\n",
    "            return np.cos(pos / (10000 ** (2 * idx / hidden_size)))\n",
    "\n",
    "        # initialize position embedding table\n",
    "        lookup_table = np.zeros((max_position_embedding, hidden_size), dtype=np.float32)\n",
    "\n",
    "        # reset table parameters with hard encoding\n",
    "        # set even dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(0, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = even_code(pos, idx)\n",
    "        # set odd dimension\n",
    "        for pos in range(max_position_embedding):\n",
    "            for idx in np.arange(1, hidden_size, step=2):\n",
    "                lookup_table[pos, idx] = odd_code(pos, idx)\n",
    "\n",
    "        return torch.tensor(lookup_table)\n",
    "\n",
    "\n",
    "\n",
    "class BertModel(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertModel, self).__init__(config)\n",
    "        self.embeddings = BertEmbeddings(config=config)\n",
    "        self.encoder = Bert.modeling.BertEncoder(config=config)\n",
    "        self.pooler = Bert.modeling.BertPooler(config)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids, attention_mask=None, output_all_encoded_layers=True):\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(age_ids)\n",
    "\n",
    "        # We create a 3D attention mask from a 2D tensor mask.\n",
    "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "        # masked positions, this operation will create a tensor which is 0.0 for\n",
    "        # positions we want to attend and -10000.0 for masked positions.\n",
    "        # Since we are adding it to the raw scores before the softmax, this is\n",
    "        # effectively the same as removing these entirely.\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype)  # fp16 compatibility\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        embedding_output = self.embeddings(nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids)\n",
    "        encoded_layers = self.encoder(embedding_output, extended_attention_mask, output_all_encoded_layers=output_all_encoded_layers)\n",
    "        \n",
    "        sequence_output = encoded_layers[-1]\n",
    "\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "        \n",
    "        if not output_all_encoded_layers:\n",
    "            encoded_layers = encoded_layers[-1]\n",
    "\n",
    "        return encoded_layers, pooled_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BertForMTR(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForMTR, self).__init__(config)\n",
    "        self.num_labels = 1\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, 1)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids, attention_mask=None, labels=None):\n",
    "        encoded_layer, pooled_output = self.bert(nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids, attention_mask, output_all_encoded_layers=False)\n",
    "\n",
    "        \n",
    "        logits = self.classifier(pooled_output).squeeze(dim=1)\n",
    "        \n",
    "        weights = torch.where(labels == 1, torch.tensor(1.5), torch.tensor(1.0))  #### à voir\n",
    "        bce_logits_loss = nn.BCEWithLogitsLoss(reduction='mean', weight=weights)\n",
    "        discr_supervised_loss = bce_logits_loss(logits, labels)\n",
    "        \n",
    "        return encoded_layer, pooled_output\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "class Pre_training2(Bert.modeling.BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(Pre_training2, self).__init__(config)\n",
    "        self.bert = BertForMTR(config)\n",
    "        self.linear1 = nn.Linear(config.hidden_size, self.config.vocab_size)\n",
    "        self.linear2 = nn.Linear(config.hidden_size, self.config.type_vocab_size -1)\n",
    "        self.gru = nn.GRU(config.hidden_size, config.hidden_size  , 1, batch_first = True, bidirectional=False)\n",
    "        self.apply(self.init_bert_weights)\n",
    "    \n",
    "    def forward(self, nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids, attention_mask=None, labels=None):\n",
    "        encoded_layer, pooled_output = self.bert(nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids, attention_mask, labels)\n",
    "        pooled_output = pooled_output.unsqueeze(dim=1)\n",
    "\n",
    "        hidden = None\n",
    "        output_sequence = []\n",
    "        nb_seq = 50\n",
    "        for i in range(nb_seq):\n",
    "            output,hidden = self.gru(pooled_output, hidden)\n",
    "            output_sequence.append(output)\n",
    "        output_sequence = torch.stack(output_sequence, dim=1).squeeze(dim=2)\n",
    "        \n",
    "        b,s,h = output_sequence.shape\n",
    "        output_sequence = output_sequence.view(b*s,h)\n",
    "        output_sequence1 = self.linear1(output_sequence)\n",
    "        output_sequence2 = self.linear2(output_sequence)\n",
    "        \n",
    "        return output_sequence1,output_sequence2\n",
    "\n",
    "\n",
    "\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.type_vocab_size = config.get('type_vocab_size')\n",
    "        self.time_vocab_size = config.get('time_vocab_size')\n",
    "        self.graph_dropout_prob = config.get('graph_dropout_prob')\n",
    "        self.node_attr_size = config.get('node_attr_size')\n",
    "\n",
    "\n",
    "\n",
    "class TrainConfig(object):\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = config.get('batch_size')\n",
    "        self.use_cuda = config.get('use_cuda')\n",
    "        self.max_len_seq = config.get('max_len_seq')\n",
    "        self.train_loader_workers = config.get('train_loader_workers')\n",
    "        self.test_loader_workers = config.get('test_loader_workers')\n",
    "        self.device = config.get('device')\n",
    "        self.output_dir = config.get('output_dir')\n",
    "        self.output_name = config.get('output_name')\n",
    "        self.best_name = config.get('best_name')\n",
    "\n",
    "\n",
    "\n",
    "class GDSet(Dataset):\n",
    "    def __init__(self, g):\n",
    "        self.g = g\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        g = self.g[index]\n",
    "        for i in range(len(g)):\n",
    "          g[i]['posi_ids'] = i\n",
    "        return g\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:06.641769Z",
     "start_time": "2024-01-11T15:52:43.128940Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(path + 'data_pad100.pkl', 'rb') as handle:\n",
    "    dataset_loaded = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:06.645176Z",
     "start_time": "2024-01-11T15:59:06.642356Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset = dataset_loaded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:07.406963Z",
     "start_time": "2024-01-11T15:59:06.644556Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('data_pad100', \"wb\") as f:\n",
    "    #pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:07.409236Z",
     "start_time": "2024-01-11T15:59:07.407511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "50\n",
      "Data(subject_id=[1], hadm_id=[1], label=[1], age=[1], rang=[1], type=[1], x=[56], edge_index=[2, 1540], edge_attr=[1540], mask_v=[1], time=[1])\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(dataset[0]))\n",
    "print(dataset[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:07.470934Z",
     "start_time": "2024-01-11T15:59:07.459634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 1055\n",
      "max noeud 9377\n",
      "node_attr_size 8\n",
      "max edge_attr 7\n",
      "age_size 48\n",
      "max age 130\n",
      "time_size 248\n",
      "max time 367\n",
      "type_size 9\n",
      "max type 10\n",
      "label_size 2\n",
      "max label 1\n",
      "hadm_size 394\n",
      "subject_size 100\n",
      "maskv_size 2\n",
      "max maskv 1\n",
      "rang_size 24\n",
      "max rang 51\n"
     ]
    }
   ],
   "source": [
    "noeud_unique = set()\n",
    "edge_attr_unique = set()\n",
    "age_unique = set()\n",
    "time_unique = set()\n",
    "type_unique = set()\n",
    "label_unique = set()\n",
    "hadm_unique = set()\n",
    "subject_unique = set()\n",
    "mask_v_unique = set()\n",
    "rang_unique = set()\n",
    "for patient in dataset:\n",
    "    for visite in patient:\n",
    "        noeuds = visite.x.tolist()\n",
    "        edge = visite.edge_attr.tolist()\n",
    "        label = visite.label.tolist()\n",
    "        age = visite.age.tolist()\n",
    "        time = visite.time.tolist()\n",
    "        typ = visite.type.tolist()\n",
    "        mask_v = visite.mask_v.tolist()\n",
    "        rang = visite.rang.tolist()\n",
    "        hadm = visite.hadm_id.tolist()\n",
    "        subject = visite.subject_id.tolist()\n",
    "        for noeud in noeuds:\n",
    "            noeud_unique.add(noeud)\n",
    "        for attribut in edge:\n",
    "            edge_attr_unique.add(attribut)\n",
    "        for lab in label:\n",
    "            label_unique.add(lab)\n",
    "        for a in age:\n",
    "            age_unique.add(a)\n",
    "        for t in time:\n",
    "            time_unique.add(t)\n",
    "        for ty in typ:\n",
    "            type_unique.add(ty)\n",
    "        for mask in mask_v:\n",
    "            mask_v_unique.add(mask)\n",
    "        for r in rang:\n",
    "            rang_unique.add(r)\n",
    "        for h in hadm:\n",
    "            hadm_unique.add(h)\n",
    "        for s in subject:\n",
    "            subject_unique.add(s)\n",
    "        \n",
    "\n",
    "vocab_size = len(noeud_unique)\n",
    "edge_attr_size = len(edge_attr_unique)\n",
    "age_size = len(age_unique)\n",
    "time_size = len(time_unique)\n",
    "type_size = len(type_unique)\n",
    "label_size = len(label_unique)\n",
    "hadm_size = len(hadm_unique)\n",
    "subject_size = len(subject_unique)\n",
    "mask_v_size = len(mask_v_unique)\n",
    "rang_size = len(rang_unique)\n",
    "\n",
    "print('vocab_size',vocab_size)\n",
    "print('max noeud',max(noeud_unique))\n",
    "print('node_attr_size',edge_attr_size)\n",
    "print('max edge_attr',max(edge_attr_unique))\n",
    "print('age_size',age_size)\n",
    "print('max age',max(age_unique))\n",
    "print('time_size',time_size)\n",
    "print('max time',max(time_unique))\n",
    "print('type_size',type_size)\n",
    "print('max type',max(type_unique))\n",
    "print('label_size',label_size)\n",
    "print('max label',max(label_unique))\n",
    "print('hadm_size',hadm_size)\n",
    "print('subject_size',subject_size)\n",
    "print('maskv_size',mask_v_size)\n",
    "print('max maskv',max(mask_v_unique))\n",
    "print('rang_size',rang_size)\n",
    "print('max rang',max(rang_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:07.473371Z",
     "start_time": "2024-01-11T15:59:07.471502Z"
    }
   },
   "outputs": [],
   "source": [
    "train_l = int(len(dataset)*0.80)\n",
    "val_l = int(len(dataset)*0.10)\n",
    "test_l = len(dataset) - val_l - train_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T15:59:07.477934Z",
     "start_time": "2024-01-11T15:59:07.474467Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, random_seed=1, few_shots=1):\n",
    "  rs = ShuffleSplit(n_splits=1, test_size=.20, random_state=random_seed)\n",
    "\n",
    "  k = 5\n",
    "\n",
    "  for i, (train_index_tmp, test_index) in enumerate(rs.split(dataset)):\n",
    "    rs2 = ShuffleSplit(n_splits=1, test_size=0.1, random_state=random_seed)\n",
    "    for j, (train_index, val_index) in enumerate(rs2.split(train_index_tmp)):\n",
    "      train_index = train_index_tmp[train_index]\n",
    "      if few_shots < 1:\n",
    "        train_index = random.sample(list(train_index), int(len(train_index) * few_shots))\n",
    "      val_index = train_index_tmp[val_index]\n",
    "\n",
    "      trainDSet = [dataset[x] for x in train_index]\n",
    "      valDSet = [dataset[x] for x in val_index]\n",
    "      testDSet = [dataset[x] for x in test_index]\n",
    "      return trainDSet, valDSet, testDSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:05:06.215977Z",
     "start_time": "2024-01-11T16:05:06.210962Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': 3,\n",
    "    'use_cuda': True,\n",
    "    'max_len_seq': 50,\n",
    "    'device': \"cuda\"if torch.cuda.is_available() else \"cpu\",\n",
    "    'data_len' : len(dataset),\n",
    "    'train_data_len' : train_l,\n",
    "    'val_data_len' : val_l,\n",
    "    'test_data_len' : test_l,\n",
    "    'epochs' : 100,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.0001,\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'vocab_size': 9405, # number of disease + symbols for word embedding\n",
    "    'edge_relationship_size': 8, # number of vocab for edge_attr\n",
    "    'hidden_size': 50*5, # word embedding and seg embedding hidden size\n",
    "    'age_vocab_size': 151, # number of vocab for age embedding\n",
    "    'time_vocab_size': 380, # number of vocab for time embedding\n",
    "    'type_vocab_size': 11+1 , # number of vocab for type embedding\n",
    "    'node_attr_size': 8, # number of vocab for node_attr embedding\n",
    "    'num_labels': 1,\n",
    "    'max_position_embedding': 50, # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.2, # dropout rate\n",
    "    'graph_dropout_prob': 0.2, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 2, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.2, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "    'n_layers' : 3 - 1,\n",
    "    'alpha' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fonction entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:12:55.505582Z",
     "start_time": "2024-01-11T16:12:55.470667Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import copy\n",
    "\n",
    "def creation_edge_index(x):\n",
    "    # Edges (graphe complet)\n",
    "    edge_index = []\n",
    "    all_edges = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i+1,len(x)):\n",
    "            all_edges.append((i, j))\n",
    "    source, target = zip(*all_edges)\n",
    "\n",
    "    edge_index = torch.tensor([source, target], dtype=torch.int64)\n",
    "\n",
    "    return edge_index\n",
    "'''\n",
    "def remove_nodes(graph_batch, max_nodes_per_visit=3):\n",
    "    num_nodes = graph_batch.x.size(0)\n",
    "    num_visits = graph_batch.batch.max() + 1\n",
    "    graph_batch2 = copy.deepcopy(graph_batch)\n",
    "    \n",
    "    nodes_to_keep = []  # Liste pour stocker les nœuds à conserver\n",
    "    nodes_to_remove = []  # Liste pour stocker les nœuds à supprimer\n",
    "    to_delete = []\n",
    "    \n",
    "    for id, visit_id in enumerate(range(num_visits)):\n",
    "        visit_nodes = (graph_batch.batch == visit_id).nonzero(as_tuple=False).squeeze()\n",
    "\n",
    "        num_nodes_in_visit = len(visit_nodes)\n",
    "        \n",
    "        if num_nodes_in_visit > max_nodes_per_visit:\n",
    "            # Choisir un nœud à supprimer au hasard\n",
    "            node_to_remove = random.choice(visit_nodes.tolist())\n",
    "            nodes_to_remove.append(node_to_remove)\n",
    "\n",
    "            # Ajouter tous les nœuds sauf celui à supprimer\n",
    "            nodes_to_keep.extend(visit_nodes[visit_nodes != node_to_remove].tolist())\n",
    "            to_delete.append(id)\n",
    "\n",
    "        else:\n",
    "            nodes_to_keep.extend(visit_nodes.tolist())\n",
    "    \n",
    "    # Supprimer les nœuds\n",
    "    print(graph_batch2.x.shape)\n",
    "    graph_batch2.x = graph_batch.x[nodes_to_keep]\n",
    "    true = graph_batch.x[nodes_to_remove]\n",
    "\n",
    "     # Supprimer les arêtes associées aux nœuds supprimés\n",
    "    edge_index = graph_batch.edge_index\n",
    "    print(edge_index)\n",
    "    print(edge_index.size(1))\n",
    "    mask = torch.ones(edge_index.size(1), dtype=torch.bool)\n",
    "    for node in nodes_to_remove:\n",
    "        mask = mask & ~((edge_index[0] == node) | (edge_index[1] == node))\n",
    "    edge_index = edge_index[:, mask]\n",
    "    \n",
    "    graph_batch2.edge_index = edge_index\n",
    "\n",
    "    # Supprimer les attributs d'arête associés aux arêtes supprimées\n",
    "    graph_batch2.edge_attr = graph_batch2.edge_attr[mask]\n",
    "\n",
    "    graph_batch2.batch = graph_batch.batch[nodes_to_keep]\n",
    "   \n",
    "    return graph_batch2, true, to_delete\n",
    "'''\n",
    "\n",
    "def rem_node(data, min_node_per_visit=3):\n",
    "    dataset2 = []\n",
    "    nodes_to_remove = []\n",
    "    indices_to_remove = []\n",
    "    for i, patient in enumerate(data):\n",
    "        patient2=[]\n",
    "        for j, visite in enumerate(patient):\n",
    "            node_initial = visite.x\n",
    "            edge_index_initial = visite.edge_index\n",
    "            edge_attr_initial = visite.edge_attr\n",
    "            batch_initial = visite.batch\n",
    "            num_nodes_in_visit = len(visite.x)\n",
    "            visit2 = copy.deepcopy(visite)\n",
    "            if num_nodes_in_visit > min_node_per_visit:\n",
    "                # Choisir un nœud à supprimer au hasard\n",
    "                node_to_remove = random.choice(node_initial.tolist()[1:])\n",
    "                nodes_to_remove.append(node_to_remove)\n",
    "                indices_to_remove.append(True)\n",
    "                visit2.x = node_initial[node_initial != node_to_remove]\n",
    "                mask = torch.ones(edge_index_initial.size(1), dtype=torch.bool)\n",
    "                mask = mask & ~ ((edge_index_initial[0] == node_to_remove) | (edge_index_initial[1] == node_to_remove))\n",
    "                visit2.edge_index = creation_edge_index(visit2.x)\n",
    "                visit2.edge_attr = edge_attr_initial[mask]\n",
    "\n",
    "                patient2.append(visit2)\n",
    "            else:\n",
    "                patient2.append(visit2)\n",
    "                indices_to_remove.append(False)\n",
    "            \n",
    "        dataset2.append(patient2)\n",
    "\n",
    "    return dataset2, torch.tensor(nodes_to_remove, dtype=torch.int64), indices_to_remove\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optim_model, trainload, device,scheduler=None):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    loss_type= torch.nn.CrossEntropyLoss()\n",
    "    loss_node = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for step, data in tqdm(enumerate(trainload)):\n",
    "        optim_model.zero_grad()\n",
    "\n",
    "        graph_batch, true_node , nodes_to_remove_idx = rem_node(data,3)\n",
    "\n",
    "        batched_data = Batch()\n",
    "        graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        nodes = graph_batch.x\n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        batch = graph_batch.batch\n",
    "        \n",
    "\n",
    "        # pour le type \n",
    "        p = graph_batch.type.shape\n",
    "        mask_type = (torch.ones(p) * 11).to(torch.int64).to(device)\n",
    "        true_type = graph_batch.type\n",
    "        graph_batch.type = mask_type\n",
    "\n",
    "\n",
    "\n",
    "        age_ids = torch.reshape(graph_batch.age, [graph_batch.age.shape[0] // 50, 50])\n",
    "        time_ids = torch.reshape(graph_batch.time, [graph_batch.time.shape[0] // 50, 50])\n",
    "        type_ids = torch.reshape(graph_batch.type, [graph_batch.type.shape[0] // 50, 50])\n",
    "        posi_ids = torch.reshape(graph_batch.posi_ids, [graph_batch.posi_ids.shape[0] // 50, 50])\n",
    "        attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "        attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "        labels = torch.reshape(graph_batch.label, [graph_batch.label.shape[0] // 50, 50])[:, -1].float()\n",
    "\n",
    "\n",
    "        pred_node, pred_type = model(nodes, edge_index, edge_attr, batch, age_ids, time_ids,type_ids,posi_ids,attMask, labels)\n",
    "        pred_node = pred_node[nodes_to_remove_idx]\n",
    "\n",
    "        loss1 = loss_type(pred_type, true_type)\n",
    "        loss2 = loss_node(pred_node, true_node.to(device))\n",
    "        total_loss = loss1 + loss2\n",
    "\n",
    "        \n",
    "        total_loss.backward()\n",
    "        tr_loss += total_loss.item()\n",
    "        optim_model.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        del loss1\n",
    "        del loss2\n",
    "        del total_loss\n",
    "        \n",
    "    \n",
    "    print(\"TOTAL TRAIN LOSS\",(tr_loss * train_params['batch_size']) / len(trainload))\n",
    "    cost = time.time() - start\n",
    "    print(\"TRAINING TIME\", cost)\n",
    "\n",
    "    return tr_loss, cost\n",
    "\n",
    "\n",
    "def eval(model, optim_model, _valload, saving, device):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    loss_type = nn.CrossEntropyLoss()\n",
    "    loss_node = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(_valload):\n",
    "            optim_model.zero_grad()\n",
    "\n",
    "            graph_batch, true_node , nodes_to_remove_idx = rem_node(data,3)\n",
    "\n",
    "            batched_data = Batch()\n",
    "            graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            nodes = graph_batch.x\n",
    "            edge_index = graph_batch.edge_index\n",
    "            edge_attr = graph_batch.edge_attr\n",
    "            batch = graph_batch.batch\n",
    "            \n",
    "\n",
    "            # pour le type \n",
    "            p = graph_batch.type.shape\n",
    "            mask_type = (torch.ones(p) * 11).to(torch.int64).to(device)\n",
    "            true_type = graph_batch.type\n",
    "            graph_batch.type = mask_type\n",
    "\n",
    "\n",
    "\n",
    "            age_ids = torch.reshape(graph_batch.age, [graph_batch.age.shape[0] // 50, 50])\n",
    "            time_ids = torch.reshape(graph_batch.time, [graph_batch.time.shape[0] // 50, 50])\n",
    "            type_ids = torch.reshape(graph_batch.type, [graph_batch.type.shape[0] // 50, 50])\n",
    "            posi_ids = torch.reshape(graph_batch.posi_ids, [graph_batch.posi_ids.shape[0] // 50, 50])\n",
    "            attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "            attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "            labels = torch.reshape(graph_batch.label, [graph_batch.label.shape[0] // 50, 50])[:, -1].float()\n",
    "\n",
    "\n",
    "            pred_node, pred_type = model(nodes, edge_index, edge_attr, batch, age_ids, time_ids,type_ids,posi_ids,attMask, labels)\n",
    "            pred_node = pred_node[nodes_to_remove_idx]\n",
    "\n",
    "            loss1 = loss_type(pred_type, true_type)\n",
    "            loss2 = loss_node(pred_node, true_node.to(device))\n",
    "            total_loss = loss1+loss2\n",
    "            tr_loss += total_loss.item()\n",
    "            del loss1\n",
    "            del loss2\n",
    "            del total_loss\n",
    "\n",
    "    print(\"TOTAL VAL LOSS\",(tr_loss * train_params['batch_size']) / len(_valload))\n",
    "\n",
    "\n",
    "    cost = time.time() - start\n",
    "    print(\"EVAL TIME\", cost)\n",
    "\n",
    "    return tr_loss, cost\n",
    "\n",
    "\n",
    "def test(testload, model, device):\n",
    "    model.eval()\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    loss_type = nn.CrossEntropyLoss()\n",
    "    loss_node = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(testload):\n",
    "            # Process the batch data and move it to the device\n",
    "\n",
    "            graph_batch, true_node , nodes_to_remove_idx = rem_node(data,3)\n",
    "\n",
    "            batched_data = Batch()\n",
    "            graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            nodes = graph_batch.x\n",
    "            edge_index = graph_batch.edge_index\n",
    "            edge_attr = graph_batch.edge_attr\n",
    "            batch = graph_batch.batch\n",
    "            \n",
    "\n",
    "            # pour le type \n",
    "            p = graph_batch.type.shape\n",
    "            mask_type = (torch.ones(p) * 11).to(torch.int64).to(device)\n",
    "            true_type = graph_batch.type\n",
    "            graph_batch.type = mask_type\n",
    "\n",
    "\n",
    "            age_ids = torch.reshape(graph_batch.age, [graph_batch.age.shape[0] // 50, 50])\n",
    "            time_ids = torch.reshape(graph_batch.time, [graph_batch.time.shape[0] // 50, 50])\n",
    "            type_ids = torch.reshape(graph_batch.type, [graph_batch.type.shape[0] // 50, 50])\n",
    "            posi_ids = torch.reshape(graph_batch.posi_ids, [graph_batch.posi_ids.shape[0] // 50, 50])\n",
    "            attMask = torch.reshape(graph_batch.mask_v, [graph_batch.mask_v.shape[0] // 50, 50])\n",
    "            attMask = torch.cat((torch.ones((attMask.shape[0], 1)).to(device), attMask), dim=1)\n",
    "            labels = torch.reshape(graph_batch.label, [graph_batch.label.shape[0] // 50, 50])[:, -1].float()\n",
    "\n",
    "\n",
    "            pred_node, pred_type = model(nodes, edge_index, edge_attr, batch, age_ids, time_ids,type_ids,posi_ids,attMask, labels)\n",
    "            pred_node = pred_node[nodes_to_remove_idx]\n",
    "\n",
    "            loss1 = loss_type(pred_type, true_type)\n",
    "            loss2 = loss_node(pred_node, true_node.to(device))\n",
    "            total_loss = loss1 + loss2\n",
    "            tr_loss += total_loss.item()\n",
    "            del loss1\n",
    "            del loss2\n",
    "            del total_loss\n",
    "\n",
    "    print(\"TOTAL TEST LOSS \", (tr_loss * train_params['batch_size']) / len(testload))\n",
    "    cost = time.time() - start\n",
    "    print(\"TEST TEST TIME\", cost)\n",
    "    \n",
    "\n",
    "    return tr_loss, cost\n",
    "\n",
    "\n",
    "\n",
    "def run_epoch(model, optim_model, trainload, valload, device,scheduler=None):\n",
    "    best_val = math.inf\n",
    "    \n",
    "    with open(path + \"v_behrt_log_train.txt\", 'a') as f:\n",
    "        f.write(\"TRAINING\\n\")\n",
    "\n",
    "    for e in range(train_params[\"epochs\"]):\n",
    "        print(\"Epoch n\" + str(e))\n",
    "\n",
    "        train_loss, train_time_cost = train(model, optim_model, trainload, device,scheduler)\n",
    "        val_loss, val_time_cost = eval(model, optim_model, valload, False, device)\n",
    "\n",
    "        train_loss = (train_loss * train_params['batch_size']) / len(trainload)\n",
    "        val_loss = (val_loss * train_params['batch_size']) / len(valload)\n",
    "        with open(path + \"GT_behrt_log_pretrain.txt\", 'a') as f:\n",
    "            f.write(\"Epoch n\" + str(e) + '\\n TRAIN {}\\t{} secs\\n'.format(train_loss, train_time_cost))\n",
    "            f.write('EVAL {}\\t{} secs\\n'.format(val_loss, val_time_cost) + '\\n\\n\\n')\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            save_model(model_to_save.state_dict(), path + 'pretrain2')\n",
    "            best_val = val_loss\n",
    "        print('\\n')\n",
    "    return train_loss, val_loss, train_time_cost, val_time_cost\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR  \n",
    "\n",
    "def experiment(num_experiments=5):\n",
    "    conf = BertConfig(model_config)\n",
    "    model = Pre_training2(conf).to(train_params['device'])\n",
    "    transformer_vars = [i for i in model.parameters()]\n",
    "    optim_model = torch.optim.AdamW(transformer_vars, lr=train_params['lr'], weight_decay=train_params['weight_decay'])\n",
    "    scheduler = None\n",
    "    df = pd.DataFrame(columns=['Experiment', 'Model', 'Metric', 'Score'])\n",
    "\n",
    "    for exp in tqdm(range(num_experiments)):\n",
    "        print(f\"\\n Experiment {exp + 1}\")\n",
    "        trainDSet, valDSet, testDSet = split_dataset(dataset, random_seed=exp)\n",
    "        trainload =  GraphLoader(GDSet(trainDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "        valload =  GraphLoader(GDSet(valDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "        testload =  GraphLoader(GDSet(testDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "        #pretrain à ajouter ici\n",
    "        train_loss, val_loss, train_time_cost, val_time_cost = run_epoch(model, optim_model, trainload, valload, train_params['device'],scheduler)\n",
    "        test_loss, test_cost = test(testload, model, train_params['device'])\n",
    "\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Train Loss', train_loss]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Val Loss', val_loss]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Train Time', train_time_cost]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Val Time', val_time_cost]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Test Time', test_cost]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Test Loss', test_loss]\n",
    "        \n",
    "    df.to_csv(path + 'GT_behrt_results.csv')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_model(_model_dict, file_name):\n",
    "    torch.save(_model_dict, file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:10:34.354541Z",
     "start_time": "2024-01-11T16:10:17.957198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment 1\n",
      "Epoch n0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 25.844415843486786\n",
      "TRAINING TIME 5.214238405227661\n",
      "TOTAL VAL LOSS 24.60110330581665\n",
      "EVAL TIME 0.37101221084594727\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 23.008140325546265\n",
      "TRAINING TIME 5.746732234954834\n",
      "TOTAL VAL LOSS 22.918253421783447\n",
      "EVAL TIME 0.4776427745819092\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 21.680137813091278\n",
      "TRAINING TIME 5.606027603149414\n",
      "TOTAL VAL LOSS 26.169431686401367\n",
      "EVAL TIME 0.4256870746612549\n",
      "\n",
      "\n",
      "Epoch n3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 20.85476052761078\n",
      "TRAINING TIME 5.64177131652832\n",
      "TOTAL VAL LOSS 21.374399662017822\n",
      "EVAL TIME 0.426922082901001\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 21.34863668680191\n",
      "TRAINING TIME 5.338130235671997\n",
      "TOTAL VAL LOSS 20.394027709960938\n",
      "EVAL TIME 0.47754740715026855\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:06,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 20.718711137771606\n",
      "TRAINING TIME 6.0542213916778564\n",
      "TOTAL VAL LOSS 22.0828275680542\n",
      "EVAL TIME 0.5438523292541504\n",
      "\n",
      "\n",
      "Epoch n6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 20.251133918762207\n",
      "TRAINING TIME 5.984379529953003\n",
      "TOTAL VAL LOSS 23.94084596633911\n",
      "EVAL TIME 0.3939831256866455\n",
      "\n",
      "\n",
      "Epoch n7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 22.23294848203659\n",
      "TRAINING TIME 5.5455756187438965\n",
      "TOTAL VAL LOSS 23.468125820159912\n",
      "EVAL TIME 0.38953161239624023\n",
      "\n",
      "\n",
      "Epoch n8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 21.154667794704437\n",
      "TRAINING TIME 5.119402647018433\n",
      "TOTAL VAL LOSS 20.983065128326416\n",
      "EVAL TIME 0.3706340789794922\n",
      "\n",
      "\n",
      "Epoch n9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.86701887845993\n",
      "TRAINING TIME 5.225611209869385\n",
      "TOTAL VAL LOSS 21.469193935394287\n",
      "EVAL TIME 0.4241516590118408\n",
      "\n",
      "\n",
      "Epoch n10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 20.066703855991364\n",
      "TRAINING TIME 5.75654149055481\n",
      "TOTAL VAL LOSS 20.330344200134277\n",
      "EVAL TIME 0.4792957305908203\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.40305107831955\n",
      "TRAINING TIME 5.836641311645508\n",
      "TOTAL VAL LOSS 19.13809061050415\n",
      "EVAL TIME 0.5106475353240967\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.441198706626892\n",
      "TRAINING TIME 5.601373672485352\n",
      "TOTAL VAL LOSS 20.46739959716797\n",
      "EVAL TIME 0.730478048324585\n",
      "\n",
      "\n",
      "Epoch n13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.947130799293518\n",
      "TRAINING TIME 4.983723402023315\n",
      "TOTAL VAL LOSS 19.661897659301758\n",
      "EVAL TIME 0.3277289867401123\n",
      "\n",
      "\n",
      "Epoch n14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.681620061397552\n",
      "TRAINING TIME 4.354038953781128\n",
      "TOTAL VAL LOSS 20.189478874206543\n",
      "EVAL TIME 0.34484219551086426\n",
      "\n",
      "\n",
      "Epoch n15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 20.56254768371582\n",
      "TRAINING TIME 4.376643657684326\n",
      "TOTAL VAL LOSS 18.97108745574951\n",
      "EVAL TIME 0.3336198329925537\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "\n",
      "\n",
      "Epoch n16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 20.0654998421669\n",
      "TRAINING TIME 4.5495383739471436\n",
      "TOTAL VAL LOSS 24.619837284088135\n",
      "EVAL TIME 0.35869598388671875\n",
      "\n",
      "\n",
      "Epoch n17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.401538729667664\n",
      "TRAINING TIME 5.0504679679870605\n",
      "TOTAL VAL LOSS 19.55725336074829\n",
      "EVAL TIME 0.38744449615478516\n",
      "\n",
      "\n",
      "Epoch n18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 18.9180548787117\n",
      "TRAINING TIME 5.011150360107422\n",
      "TOTAL VAL LOSS 22.403276920318604\n",
      "EVAL TIME 0.342393159866333\n",
      "\n",
      "\n",
      "Epoch n19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.48395347595215\n",
      "TRAINING TIME 4.875501394271851\n",
      "TOTAL VAL LOSS 21.544434070587158\n",
      "EVAL TIME 0.31901049613952637\n",
      "\n",
      "\n",
      "Epoch n20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.63357013463974\n",
      "TRAINING TIME 4.726126670837402\n",
      "TOTAL VAL LOSS 19.34280490875244\n",
      "EVAL TIME 0.36465024948120117\n",
      "\n",
      "\n",
      "Epoch n21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 19.47041690349579\n",
      "TRAINING TIME 5.833360910415649\n",
      "TOTAL VAL LOSS 22.27788019180298\n",
      "EVAL TIME 0.32999634742736816\n",
      "\n",
      "\n",
      "Epoch n22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:04,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 18.814604818820953\n",
      "TRAINING TIME 4.904999732971191\n",
      "TOTAL VAL LOSS 20.865407466888428\n",
      "EVAL TIME 0.3858494758605957\n",
      "\n",
      "\n",
      "Epoch n23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:04,  4.08it/s]\n",
      "  0%|          | 0/1 [02:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_experiments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[118], line 327\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(num_experiments)\u001b[0m\n\u001b[1;32m    325\u001b[0m testload \u001b[38;5;241m=\u001b[39m  GraphLoader(GDSet(testDSet), batch_size\u001b[38;5;241m=\u001b[39mtrain_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m#pretrain à ajouter ici\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m train_loss, val_loss, train_time_cost, val_time_cost \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m test_loss, test_cost \u001b[38;5;241m=\u001b[39m test(testload, model, train_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    330\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df)] \u001b[38;5;241m=\u001b[39m [exp \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT_BERT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, train_loss]\n",
      "Cell \u001b[0;32mIn[118], line 293\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, optim_model, trainload, valload, device, scheduler)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch n\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m--> 293\u001b[0m     train_loss, train_time_cost \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     val_loss, val_time_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, optim_model, valload, \u001b[38;5;28;01mFalse\u001b[39;00m, device)\n\u001b[1;32m    296\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m (train_loss \u001b[38;5;241m*\u001b[39m train_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(trainload)\n",
      "Cell \u001b[0;32mIn[118], line 143\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optim_model, trainload, device, scheduler)\u001b[0m\n\u001b[1;32m    139\u001b[0m attMask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((torch\u001b[38;5;241m.\u001b[39mones((attMask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device), attMask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    140\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(graph_batch\u001b[38;5;241m.\u001b[39mlabel, [graph_batch\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m])[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 143\u001b[0m pred_node, pred_type \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtype_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mposi_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattMask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m pred_node \u001b[38;5;241m=\u001b[39m pred_node[nodes_to_remove_idx]\n\u001b[1;32m    146\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m loss_type(pred_type, true_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[59], line 313\u001b[0m, in \u001b[0;36mPre_training2.forward\u001b[0;34m(self, nodes, edge_index, edge_attr, batch, age_ids, time_ids, type_ids, posi_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m    311\u001b[0m nb_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_seq):\n\u001b[0;32m--> 313\u001b[0m     output,hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpooled_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     output_sequence\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    315\u001b[0m output_sequence \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(output_sequence, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1106\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time as time\n",
    "\n",
    "df = experiment(num_experiments=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:11:06.777571Z",
     "start_time": "2024-01-11T16:11:06.770550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GT_BERT</td>\n",
       "      <td>Train Loss</td>\n",
       "      <td>44.956565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GT_BERT</td>\n",
       "      <td>Val Loss</td>\n",
       "      <td>42.408109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>GT_BERT</td>\n",
       "      <td>Train Time</td>\n",
       "      <td>5.391731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GT_BERT</td>\n",
       "      <td>Val Time</td>\n",
       "      <td>0.187244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>GT_BERT</td>\n",
       "      <td>Test Time</td>\n",
       "      <td>0.485468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experiment    Model      Metric      Score\n",
       "0           1  GT_BERT  Train Loss  44.956565\n",
       "1           1  GT_BERT    Val Loss  42.408109\n",
       "2           1  GT_BERT  Train Time   5.391731\n",
       "3           1  GT_BERT    Val Time   0.187244\n",
       "4           1  GT_BERT   Test Time   0.485468"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:11:25.648376Z",
     "start_time": "2024-01-11T16:11:25.641958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model         Metric  Average Score  Standard Deviation\n",
      "0  GT_BERT     Test AUPRC           0.06                 NaN\n",
      "1  GT_BERT     Test AUROC           0.22                 NaN\n",
      "2  GT_BERT  Test Accuracy           0.90                 NaN\n",
      "3  GT_BERT        Test F1           0.85                 NaN\n",
      "4  GT_BERT      Test Time           0.15                 NaN\n",
      "5  GT_BERT     Train Loss           2.32                 NaN\n",
      "6  GT_BERT     Train Time           2.80                 NaN\n",
      "7  GT_BERT   Val Accuracy           0.60                 NaN\n",
      "8  GT_BERT       Val Loss           4.07                 NaN\n",
      "9  GT_BERT       Val Time           0.31                 NaN\n"
     ]
    }
   ],
   "source": [
    "# Group by Model and Metric and calculate average and standard deviation\n",
    "result_df = df.groupby(['Model', 'Metric']).agg({'Score': ['mean', 'std']}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "result_df.columns = ['Model', 'Metric', 'Average Score', 'Standard Deviation']\n",
    "\n",
    "result_df['Average Score'] = result_df['Average Score'].round(2)\n",
    "result_df['Standard Deviation'] = result_df['Standard Deviation'].round(2)\n",
    "\n",
    "# Print the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T16:11:30.404747Z",
     "start_time": "2024-01-11T16:11:30.389770Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_parameters\u001b[39m(model):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m----> 3\u001b[0m count_parameters(\u001b[43mmodel\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters())\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
