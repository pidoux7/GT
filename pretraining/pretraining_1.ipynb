{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3309d60ce9652b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Importing Libraries ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:53.604651Z",
     "start_time": "2024-01-21T11:20:36.939044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import_ipynb in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.1.3)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.6.2)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2.1.0)\r\n",
      "Requirement already satisfied: numpy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (1.26.2)\r\n",
      "Requirement already satisfied: boto3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (1.34.11)\r\n",
      "Requirement already satisfied: requests in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (4.47.0)\r\n",
      "Requirement already satisfied: regex in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from pytorch_pretrained_bert) (2023.12.25)\r\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.12.2)\r\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.11 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (1.34.11)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->pytorch_pretrained_bert) (2023.11.17)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.11->boto3->pytorch_pretrained_bert) (2.8.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.11->boto3->pytorch_pretrained_bert) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: sparse in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.14.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (1.26.2)\r\n",
      "Requirement already satisfied: scipy>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (1.11.4)\r\n",
      "Requirement already satisfied: numba>=0.49 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sparse) (0.58.1)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from numba>=0.49->sparse) (0.41.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: transformers in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (4.36.2)\r\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.20.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (1.26.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.15.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (0.4.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from transformers) (4.47.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: torchmetrics in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (1.2.1)\r\n",
      "Requirement already satisfied: numpy>1.20.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (1.26.2)\r\n",
      "Requirement already satisfied: packaging>17.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (23.2)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (2.1.0)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torchmetrics) (0.10.0)\r\n",
      "Requirement already satisfied: setuptools in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\r\n",
      "Requirement already satisfied: filelock in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from torch>=1.8.1->torchmetrics) (2023.12.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "2.1.0\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install import_ipynb\n",
    "!pip install -U -q PyDrive\n",
    "!pip install pytorch_pretrained_bert\n",
    "!pip install sparse\n",
    "!pip install transformers\n",
    "!pip install torchmetrics\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fd4fd9552085c2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:54.857401Z",
     "start_time": "2024-01-21T11:20:53.603933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages (0.7.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e0e82211314cd0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.422686Z",
     "start_time": "2024-01-21T11:20:54.859621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_geometric/typing.py:63: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: dlopen(/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_scatter/_scatter_cpu.so, 0x0006): Symbol not found: __ZN5torch8autograd13_wrap_outputsERKNSt3__16vectorIN2at6TensorENS1_9allocatorIS4_EEEERKNS1_13unordered_setIPN3c1010TensorImplENS1_4hashISD_EENS1_8equal_toISD_EENS5_ISD_EEEESL_NSB_8ArrayRefINSB_8optionalIS4_EEEERKNS1_10shared_ptrINS0_4NodeEEENS1_8functionIFS7_S7_S7_EEE\n",
      "  Referenced from: <BEF9F452-9D77-323E-91B8-AF667F303838> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_scatter/_scatter_cpu.so\n",
      "  Expected in:     <66FB8649-BB87-3CD6-A177-462038DCAE02> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_geometric/typing.py:101: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_sparse/_spmm_cpu.so, 0x0006): Symbol not found: __ZN5torch8autograd13_wrap_outputsERKNSt3__16vectorIN2at6TensorENS1_9allocatorIS4_EEEERKNS1_13unordered_setIPN3c1010TensorImplENS1_4hashISD_EENS1_8equal_toISD_EENS5_ISD_EEEESL_NSB_8ArrayRefINSB_8optionalIS4_EEEERKNS1_10shared_ptrINS0_4NodeEEENS1_8functionIFS7_S7_S7_EEE\n",
      "  Referenced from: <4D05D979-F268-321D-A145-18B3BDA59213> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_sparse/_spmm_cpu.so\n",
      "  Expected in:     <66FB8649-BB87-3CD6-A177-462038DCAE02> /Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once per notebook.\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import numpy as np\n",
    "import sparse\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as tgmnn\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.loader import DataListLoader as GraphLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "import sklearn.metrics as skm\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import pytorch_pretrained_bert as Bert\n",
    "import itertools\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import ast\n",
    "from typing import Optional, Tuple, Union\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# if you are using a mac this cell aims to solve this error: \n",
    "# NotImplementedError: The operator 'aten::scatter_reduce.two_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable ⁠ PYTORCH_ENABLE_MPS_FALLBACK=1 ⁠ to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\n",
    "\n",
    "# You will probably need first to execute this bash command in your terminal: touch .zshenv && echo 'export PYTORCH_ENABLE_MPS_FALLBACK=1' >> .zshenv\n",
    "# And then restart the notebook\n",
    "\n",
    "#import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.425165Z",
     "start_time": "2024-01-21T11:20:57.423420Z"
    }
   },
   "id": "2f8a5093d5adb88f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Start tensorboard ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "907727436e6962d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %reload_ext tensorboard\n",
    "# # %tensorboard --logdir $log_dir --port 6006"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.430620Z",
     "start_time": "2024-01-21T11:20:57.425519Z"
    }
   },
   "id": "28d968c06dab59b6",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#################################################### Defining classes ####################################################"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a93aef5aba8cac70"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4d4485cac2fe92",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.439312Z",
     "start_time": "2024-01-21T11:20:57.434832Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### Transformer Conv ###############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class TransformerConv(MessagePassing):\n",
    "    _alpha: OptTensor\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        heads: int = 1,\n",
    "        concat: bool = True,\n",
    "        beta: bool = False,\n",
    "        dropout: float = 0.,\n",
    "        edge_dim: Optional[int] = None,\n",
    "        bias: bool = True,\n",
    "        root_weight: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.beta = beta and root_weight\n",
    "        self.root_weight = root_weight\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        self.edge_dim = edge_dim\n",
    "        self._alpha = None\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
    "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
    "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
    "        self.layernorm1 = LayerNorm(out_channels)\n",
    "        self.layernorm2 = LayerNorm(out_channels)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.proj = Linear(heads * out_channels, out_channels)\n",
    "        self.ffn = Linear(out_channels, out_channels)\n",
    "        self.ffn2 = Linear(out_channels, out_channels)\n",
    "        if edge_dim is not None:\n",
    "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
    "        else:\n",
    "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
    "\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.lin_key.reset_parameters()\n",
    "        self.lin_query.reset_parameters()\n",
    "        self.lin_value.reset_parameters()\n",
    "        if self.edge_dim:\n",
    "            self.lin_edge.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
    "                edge_attr: OptTensor = None, batch=None, return_attention_weights=None):\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, NoneType) -> Tensor  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], Tensor, OptTensor, bool) -> Tuple[Tensor, Tuple[Tensor, Tensor]]  # noqa\n",
    "        # type: (Union[Tensor, PairTensor], SparseTensor, OptTensor, bool) -> Tuple[Tensor, SparseTensor]  # noqa\n",
    "        r\"\"\"Runs the forward pass of the module.\n",
    "\n",
    "        Args:\n",
    "            return_attention_weights (bool, optional): If set to :obj:`True`,\n",
    "                will additionally return the tuple\n",
    "                :obj:`(edge_index, attention_weights)`, holding the computed\n",
    "                attention weights for each edge. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        H, C = self.heads, self.out_channels\n",
    "        residual = x\n",
    "        x = self.layernorm1(x, batch)\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "        query = self.lin_query(x[1]).view(-1, H, C)\n",
    "        key = self.lin_key(x[0]).view(-1, H, C)\n",
    "        value = self.lin_value(x[0]).view(-1, H, C)\n",
    "        # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa\n",
    "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
    "                             edge_attr=edge_attr, size=None)\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "        if self.concat:\n",
    "            out = self.proj(out.view(-1, self.heads * self.out_channels))\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out+residual\n",
    "        residual = out\n",
    "\n",
    "        out = self.layernorm2(out)\n",
    "        out = self.gelu(self.ffn(out))\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = self.ffn2(out)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "        out = out + residual\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            assert alpha is not None\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                return out, (edge_index, alpha)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                return out, edge_index.set_value(alpha, layout='coo')\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
    "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
    "                size_i: Optional[int]) -> Tensor:\n",
    "\n",
    "\n",
    "        if self.lin_edge is not None:\n",
    "            assert edge_attr is not None\n",
    "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,\n",
    "                                                      self.out_channels)\n",
    "            key_j = key_j + edge_attr\n",
    "\n",
    "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = value_j\n",
    "        if edge_attr is not None:\n",
    "            out = out + edge_attr\n",
    "\n",
    "        out = out * alpha.view(-1, self.heads, 1)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, heads={self.heads})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f416b0d45c5ca51c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.440892Z",
     "start_time": "2024-01-21T11:20:57.438956Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "###################################################### Graph Transformer ###############################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class GraphTransformer(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformerconv1 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv2 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=True)\n",
    "        self.transformerconv3 = TransformerConv(config.hidden_size // 5, config.hidden_size // 5, heads=2, edge_dim=config.hidden_size // 5, dropout=config.hidden_dropout_prob, concat=False)\n",
    "        \n",
    "        self.embed = nn.Embedding(config.vocab_size, config.hidden_size // 5) \n",
    "        self.embed_ee = nn.Embedding(config.node_attr_size, config.hidden_size // 5)\n",
    "                    \n",
    "\n",
    "    def forward(self, x, edge_index, edge_index_readout, edge_attr, batch):\n",
    "        #print(\"GT\")\n",
    "        indices = (x==0).nonzero().squeeze()\n",
    "        h_nodes = self.transformerconv1(x=self.embed(x), edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv2(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        h_nodes = nn.GELU()(h_nodes)\n",
    "        h_nodes = self.transformerconv3(x=h_nodes, edge_index=edge_index, edge_attr=self.embed_ee(edge_attr), batch=batch)\n",
    "        x = h_nodes[indices]\n",
    "        return x, h_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c6b6ff5ca752b7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.453670Z",
     "start_time": "2024-01-21T11:20:57.442050Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "######################################################## Bert Config ##################################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class BertConfig(Bert.modeling.BertConfig):\n",
    "    def __init__(self, config):\n",
    "        super(BertConfig, self).__init__(\n",
    "            vocab_size_or_config_json_file=config.get('vocab_size'),\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_hidden_layers=config.get('num_hidden_layers'),\n",
    "            num_attention_heads=config.get('num_attention_heads'),\n",
    "            intermediate_size=config.get('intermediate_size'),\n",
    "            hidden_act=config.get('hidden_act'),\n",
    "            hidden_dropout_prob=config.get('hidden_dropout_prob'),\n",
    "            attention_probs_dropout_prob=config.get('attention_probs_dropout_prob'),\n",
    "            max_position_embeddings = config.get('max_position_embedding'),\n",
    "            initializer_range=config.get('initializer_range'),\n",
    "        )\n",
    "        self.age_vocab_size = config.get('age_vocab_size')\n",
    "        self.type_vocab_size = config.get('type_vocab_size')\n",
    "        self.time_vocab_size = config.get('time_vocab_size')\n",
    "        self.graph_dropout_prob = config.get('graph_dropout_prob')\n",
    "        self.node_attr_size = config.get('node_attr_size')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7c1dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.454721Z",
     "start_time": "2024-01-21T11:20:57.444742Z"
    }
   },
   "outputs": [],
   "source": [
    "class Pre_training_1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Pre_training_1, self).__init__()\n",
    "        self.config = config\n",
    "        self.gnn = GraphTransformer(config)\n",
    "        self.linear = nn.Linear(self.config.hidden_size // 5, self.config.vocab_size)\n",
    "        self.layers = nn.ModuleList([self.gnn, self.linear])\n",
    "\n",
    "    def forward(self, nodes, edge_index, edge_index_readout, edge_attr, batch):\n",
    "        # Define the forward pass using self.gnn and self.linear as needed\n",
    "        vst,x = self.gnn(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e351bc79848c792a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.455514Z",
     "start_time": "2024-01-21T11:20:57.448635Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "############################################################ GDSet ####################################################################\n",
    "#######################################################################################################################################\n",
    "\n",
    "class GDSet(Dataset):\n",
    "    def __init__(self, g):\n",
    "        self.g = g\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        g = self.g[index]\n",
    "        for i in range(len(g)):\n",
    "          g[i]['posi_ids'] = i\n",
    "        return g\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af27382901bf1746",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Importing Data ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = '../../data/'\n",
    "path_results = '../../results/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:57.455934Z",
     "start_time": "2024-01-21T11:20:57.450520Z"
    }
   },
   "id": "532b044cc487cb7c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81192e04deabcfb9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.700872Z",
     "start_time": "2024-01-21T11:20:57.452429Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(path + 'data_pad100.pkl', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db8d113daefd13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##################################################### Splitting Data ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36bd142a2914b09e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.702963Z",
     "start_time": "2024-01-21T11:20:58.701113Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################################################\n",
    "pourcentage_nodes_to_mask = 0.15\n",
    "labels_masked_nodes = []\n",
    "mask_node_embeddings = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f332815fae943e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.707557Z",
     "start_time": "2024-01-21T11:20:58.704192Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train_params, random_seed=1):\n",
    "  rs = ShuffleSplit(n_splits=1, test_size=train_params.get('test_split'), random_state=random_seed)\n",
    "\n",
    "  for i, (train_index_tmp, test_index) in enumerate(rs.split(dataset)):\n",
    "    rs2 = ShuffleSplit(n_splits=1, test_size=train_params.get('val_split'), random_state=random_seed)\n",
    "    \n",
    "    for j, (train_index, val_index) in enumerate(rs2.split(train_index_tmp)):\n",
    "      train_index = train_index_tmp[train_index]\n",
    "      val_index = train_index_tmp[val_index]\n",
    "      trainDSet = [dataset[x] for x in train_index]\n",
    "      valDSet = [dataset[x] for x in val_index]\n",
    "      testDSet = [dataset[x] for x in test_index]\n",
    "\n",
    "      return trainDSet, valDSet, testDSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a004db21db04ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###################################################### Config Files ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2724e7a55d6dadc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.728324Z",
     "start_time": "2024-01-21T11:20:58.720944Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': 5,\n",
    "    'max_len_seq': 50,\n",
    "    'device': \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"),\n",
    "    #'device': \"cpu\",\n",
    "    'data_len' : len(dataset),\n",
    "    'val_split' : 0.1,\n",
    "    'test_split' : 0.2,\n",
    "    'train_data_len' : int(0.9*0.8*len(dataset)),   # the train dataset is 90% of 80% of the whole dataset\n",
    "    'val_data_len' : int(0.1*0.8*len(dataset)),   # the validation dataset is 10% of 80% of the whole dataset\n",
    "    'test_data_len' : int(0.2*len(dataset)),   # the test dataset is 20% of the whole dataset\n",
    "    'epochs' : 15,\n",
    "    'lr': 0.0001,\n",
    "    'weight_decay': 0.0001\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'vocab_size': 9405, # number of disease + symbols for word embedding (avec vst) + 1 for mask\n",
    "    'edge_relationship_size': 8, # number of vocab for edge_attr\n",
    "    'hidden_size': 50*5, # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2, # number of vocab for seg embedding\n",
    "    'age_vocab_size': 151, # number of vocab for age embedding\n",
    "    'time_vocab_size': 380, # number of vocab for time embedding\n",
    "    'type_vocab_size': 11+1, # number of vocab for type embedding + 1 for mask\n",
    "    'node_attr_size': 8, # number of vocab for node_attr embedding\n",
    "    'num_labels':1,\n",
    "    'max_position_embedding': 50, # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.2, # dropout rate\n",
    "    'graph_dropout_prob': 0.2, # dropout rate\n",
    "    'num_hidden_layers': 6, # number of multi-head attention layers required\n",
    "    'num_attention_heads': 2, # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.2, # multi-head attention dropout rate\n",
    "    'intermediate_size': 512, # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu', # The non-linear activation function in the encoder and the pooler \"gelu\", 'relu', 'swish' are supported\n",
    "    'initializer_range': 0.02, # parameter weight initializer range\n",
    "    'n_layers' : 3 - 1,\n",
    "    'alpha' : 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4fe3f5c666bab2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "######################################################## DEVICE ##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c787c2405763db0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.728881Z",
     "start_time": "2024-01-21T11:20:58.722990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  mps\n"
     ]
    }
   ],
   "source": [
    "# print which device is used\n",
    "print('device: ', train_params['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb286a7f3cab35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#################################################### Training Functions ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f469dbb0caa05f8e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.732505Z",
     "start_time": "2024-01-21T11:20:58.728721Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optim, trainload, device, writer, epoch):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    CE_loss = torch.nn.CrossEntropyLoss(ignore_index=3)\n",
    "    \n",
    "    for step, data in tqdm(enumerate(trainload)):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        batched_data = Batch()\n",
    "        graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        nodes = graph_batch.x\n",
    "                \n",
    "        list_index = [i for i in range(nodes.shape[0])]\n",
    "        random.shuffle(list_index)\n",
    "        index_nodes_to_mask = list_index[:int((nodes.shape[0]) * pourcentage_nodes_to_mask)]\n",
    "        index_nodes_not_masked = list(set(list_index) - set(index_nodes_to_mask))\n",
    "        labels_nodes = nodes\n",
    "        ytrue = nodes\n",
    "\n",
    "        labels_nodes[index_nodes_not_masked] = 3\n",
    "        nodes[index_nodes_to_mask] = mask_node_embeddings\n",
    "        \n",
    "        edge_index = graph_batch.edge_index\n",
    "        edge_index_readout = graph_batch.edge_index\n",
    "        edge_attr = graph_batch.edge_attr\n",
    "        batch = graph_batch.batch\n",
    "\n",
    "        pred = model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "        \n",
    "        loss = CE_loss(pred, labels_nodes)\n",
    "        # Update TensorBoard for train loss per iteration\n",
    "        writer.add_scalar('Train Loss per Iteration', loss.item(), epoch * len(trainload) + step)\n",
    "        \n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "        optim.step()\n",
    "\n",
    "        del loss\n",
    "\n",
    "    print(\"TOTAL TRAIN LOSS\", (tr_loss * train_params['batch_size']) / len(trainload))\n",
    "    cost = time.time() - start\n",
    "    \n",
    "    # Update TensorBoard for total train loss per epoch\n",
    "    writer.add_scalar('Total Train Loss per Epoch', (tr_loss * train_params['batch_size']) / len(trainload), epoch)\n",
    "    \n",
    "    return tr_loss, cost, pred,ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98d4b3ccd3dccc1f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.738946Z",
     "start_time": "2024-01-21T11:20:58.732733Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval(model, _valload, device, writer, epoch):\n",
    "    tr_loss = 0\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    CE_loss = torch.nn.CrossEntropyLoss(ignore_index=3)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, data in tqdm(enumerate(_valload)):\n",
    "            batched_data = Batch()\n",
    "            graph_batch = batched_data.from_data_list(list(itertools.chain.from_iterable(data)))\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            nodes = graph_batch.x\n",
    "                    \n",
    "            list_index = [i for i in range(nodes.shape[0])]\n",
    "            random.shuffle(list_index)\n",
    "            index_nodes_to_mask = list_index[:int((nodes.shape[0]) * pourcentage_nodes_to_mask)]\n",
    "            index_nodes_not_masked = list(set(list_index) - set(index_nodes_to_mask))\n",
    "            labels_nodes = nodes\n",
    "            ytrue = nodes\n",
    "            \n",
    "            labels_nodes[index_nodes_not_masked] = 3\n",
    "            nodes[index_nodes_to_mask] = mask_node_embeddings\n",
    "            \n",
    "            edge_index = graph_batch.edge_index\n",
    "            edge_index_readout = graph_batch.edge_index\n",
    "            edge_attr = graph_batch.edge_attr\n",
    "            batch = graph_batch.batch\n",
    "\n",
    "            pred = model(nodes, edge_index, edge_index_readout, edge_attr, batch)\n",
    "\n",
    "            loss = CE_loss(pred, labels_nodes)\n",
    "            # Update TensorBoard for eval loss per iteration\n",
    "            writer.add_scalar('Eval Loss per Iteration', loss.item(), epoch * len(_valload) + step)\n",
    "            \n",
    "            tr_loss += loss.item()\n",
    "            \n",
    "            del loss\n",
    "\n",
    "    print(\"TOTAL EVAL LOSS\", (tr_loss * train_params['batch_size']) / len(_valload))\n",
    "    \n",
    "    # Update TensorBoard for total eval loss per epoch\n",
    "    writer.add_scalar('Total Eval Loss per Epoch', (tr_loss * train_params['batch_size']) / len(_valload), epoch)\n",
    "    \n",
    "    cost = time.time() - start\n",
    "    return tr_loss, cost, pred, ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e74b020a899d96a8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.740194Z",
     "start_time": "2024-01-21T11:20:58.737356Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, optim_model, trainload, valload, device, exp, writer):\n",
    "    best_val = math.inf\n",
    "    loss_train_liste = []\n",
    "    loss_val_liste = []\n",
    "    \n",
    "    for e in tqdm(range(train_params[\"epochs\"])):\n",
    "        print(\"Epoch n\" + str(e))\n",
    "        train_loss, train_time_cost, pred_train, ytrue_train = train(model, optim_model, trainload, device, writer, e)\n",
    "        val_loss, val_time_cost, pred_eval, ytrue_eval = eval(model, valload, device, writer, e)\n",
    "        accuracy_train = skm.accuracy_score(ytrue_train.cpu().detach().numpy(), pred_train.cpu().detach().numpy().argmax(axis=1))\n",
    "        accuracy_eval = skm.accuracy_score(ytrue_eval.cpu().detach().numpy(), pred_eval.cpu().detach().numpy().argmax(axis=1))\n",
    "\n",
    "        train_loss = (train_loss * train_params['batch_size']) / len(trainload)\n",
    "        val_loss = (val_loss * train_params['batch_size']) / len(valload)\n",
    "        loss_train_liste.append(train_loss)\n",
    "        loss_val_liste.append(val_loss)\n",
    "        print('TRAIN \\t{} secs'.format(train_time_cost))\n",
    "        print(f'TRAIN accuracy : {accuracy_train}')\n",
    "        \n",
    "        with open(path_results + 'losses_and_times/' + \"pre_training_1_log_train_\" + f'{exp}' + \".txt\", 'a') as f:\n",
    "            f.write(\"Epoch n\" + str(e) + '\\n TRAIN {}\\t{} secs\\n'.format(train_loss, train_time_cost))\n",
    "            f.write('EVAL {}\\t{} secs\\n'.format(val_loss, val_time_cost) + '\\n\\n\\n')\n",
    "        print('EVAL \\t{} secs'.format(val_time_cost))\n",
    "        print('EVAL accuracy : {}\\n\\n'.format(accuracy_eval))\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            print(\"** ** * Saving fine - tuned model ** ** * \")\n",
    "            torch.save(model.gnn.state_dict(), path_results + 'weights/' + 'GraphTransformer_pretrain_1_num_' + f'{exp}' + '.pch')\n",
    "            best_val = val_loss\n",
    "            \n",
    "    epoch = [i for i in range(train_params[\"epochs\"])]\n",
    "    plt.plot(epoch, loss_train_liste)\n",
    "    plt.legend(['train'])\n",
    "    plt.plot(epoch,loss_val_liste)\n",
    "    plt.legend(['val'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig(path_results + 'plots/' + 'Pre_training_1.png')\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, val_loss, accuracy_train, accuracy_eval, train_time_cost, val_time_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedbac940be492c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "################################################### Experiences ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def experiment(num_experiments=5):\n",
    "    conf = BertConfig(model_config)\n",
    "    df = pd.DataFrame(columns=['Experiment', 'Model', 'Metric', 'Score'])\n",
    "\n",
    "    for exp in tqdm(range(num_experiments)):\n",
    "        model = Pre_training_1(conf).to(train_params['device'])\n",
    "        transformer_vars = [i for i in model.parameters()]\n",
    "        optim_model = torch.optim.AdamW(transformer_vars, lr=train_params['lr'], weight_decay=train_params['weight_decay'])\n",
    "\n",
    "        # Set log directory for TensorBoard\n",
    "        writer = SummaryWriter(path_results + 'runs/' + 'pre_training_1/' + str(exp + 1))\n",
    "\n",
    "\n",
    "        print(f\"\\n Experiment {exp + 1}\")\n",
    "        trainDSet, valDSet, testDSet = split_dataset(dataset, train_params, random_seed=exp)\n",
    "        trainload = GraphLoader(GDSet(trainDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "        valload = GraphLoader(GDSet(valDSet), batch_size=train_params['batch_size'], shuffle=False)\n",
    "\n",
    "        train_loss, val_loss, accuracy_train, accuracy_eval, train_time_cost, val_time_cost = run_epoch(\n",
    "            model, optim_model, trainload, valload, train_params['device'], exp, writer\n",
    "        )\n",
    "\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Val Accuracy', accuracy_eval]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Train Loss', train_loss]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Val Loss', val_loss]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Train Time', train_time_cost]\n",
    "        df.loc[len(df)] = [exp + 1, 'GT_BERT', 'Val Time', val_time_cost]\n",
    "\n",
    "        # Close the writer for the current experiment\n",
    "        writer.close()\n",
    "\n",
    "    df.to_csv(path_results + 'dataframes/' + 'GT_behrt_results_pretraining_1.csv')\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:20:58.746417Z",
     "start_time": "2024-01-21T11:20:58.741464Z"
    }
   },
   "id": "f0d104d43e45d3da",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "d25222bec6977e32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "######################################################## Main #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment 1\n",
      "Epoch n0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garance/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:94: UserWarning: The operator 'aten::scatter_reduce.two_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return src.new_zeros(size).scatter_reduce_(\n",
      "\n",
      "\n",
      "1it [00:05,  5.70s/it]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:08,  4.80s/it]\u001B[A\u001B[A\n",
      "\n",
      "3it [00:10,  4.14s/it]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:13,  3.68s/it]\u001B[A\u001B[A\n",
      "\n",
      "5it [00:16,  3.39s/it]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:19,  3.19s/it]\u001B[A\u001B[A\n",
      "\n",
      "7it [00:21,  3.06s/it]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:24,  2.96s/it]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:27,  2.90s/it]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:30,  2.96s/it]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:33,  2.97s/it]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:36,  2.96s/it]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:39,  2.96s/it]\u001B[A\u001B[A\n",
      "\n",
      "14it [00:42,  2.96s/it]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:45,  3.03s/it]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 44.54426638285319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:01,  1.74s/it]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:03,  1.90s/it]\u001B[A\u001B[A\n",
      "\n",
      "  7%|▋         | 1/15 [00:49<11:30, 49.34s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "1it [00:00,  8.07it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 41.25795841217041\n",
      "TRAIN \t45.50439500808716 secs\n",
      "TRAIN accuracy : 0.0\n",
      "EVAL \t3.796976089477539 secs\n",
      "EVAL accuracy : 0.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3it [00:00,  9.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "5it [00:00, 10.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "7it [00:00, 10.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:00, 11.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:01,  9.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:01, 10.22it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 39.32it/s][A\n",
      "\n",
      " 13%|█▎        | 2/15 [00:50<07:34, 34.97s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 39.27411222457886\n",
      "TOTAL EVAL LOSS 36.456639766693115\n",
      "TRAIN \t1.3599011898040771 secs\n",
      "TRAIN accuracy : 0.08342480790340286\n",
      "EVAL \t0.052001953125 secs\n",
      "EVAL accuracy : 0.09302325581395349\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 11.78it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 11.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 11.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 11.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.01it/s][A\n",
      "\n",
      " 20%|██        | 3/15 [00:52<04:58, 24.89s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 34.469208081563316\n",
      "TOTAL EVAL LOSS 31.89697504043579\n",
      "TRAIN \t1.3181259632110596 secs\n",
      "TRAIN accuracy : 0.12952799121844127\n",
      "EVAL \t0.04985499382019043 secs\n",
      "EVAL accuracy : 0.08879492600422834\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 11.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.29it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 42.99it/s][A\n",
      "\n",
      " 27%|██▋       | 4/15 [00:53<03:16, 17.84s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 29.093619028727215\n",
      "TOTAL EVAL LOSS 26.479170322418213\n",
      "TRAIN \t1.3294191360473633 secs\n",
      "TRAIN accuracy : 0.12952799121844127\n",
      "EVAL \t0.047699928283691406 secs\n",
      "EVAL accuracy : 0.10359408033826638\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.55it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00, 10.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 11.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.58it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.86it/s][A\n",
      "\n",
      " 33%|███▎      | 5/15 [00:54<02:09, 12.90s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 23.325904369354248\n",
      "TOTAL EVAL LOSS 21.395440101623535\n",
      "TRAIN \t1.296839952468872 secs\n",
      "TRAIN accuracy : 0.13172338090010977\n",
      "EVAL \t0.04876518249511719 secs\n",
      "EVAL accuracy : 0.09513742071881606\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.52it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.06it/s][A\n",
      "\n",
      " 40%|████      | 6/15 [00:56<01:25,  9.45s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 16.949893633524578\n",
      "TOTAL EVAL LOSS 15.287155508995056\n",
      "TRAIN \t1.3357748985290527 secs\n",
      "TRAIN accuracy : 0.13172338090010977\n",
      "EVAL \t0.05106306076049805 secs\n",
      "EVAL accuracy : 0.09936575052854123\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 11.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.00it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 11.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.06it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 37.94it/s][A\n",
      "\n",
      " 47%|████▋     | 7/15 [00:57<00:56,  7.05s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 12.819836576779684\n",
      "TOTAL EVAL LOSS 12.447347044944763\n",
      "TRAIN \t1.3568241596221924 secs\n",
      "TRAIN accuracy : 0.14270032930845225\n",
      "EVAL \t0.0538177490234375 secs\n",
      "EVAL accuracy : 0.11627906976744186\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.17it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.13it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 11.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.53it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 10.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 36.43it/s][A\n",
      "\n",
      " 53%|█████▎    | 8/15 [00:59<00:37,  5.37s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 11.147570610046387\n",
      "TOTAL EVAL LOSS 10.738543272018433\n",
      "TRAIN \t1.3770928382873535 secs\n",
      "TRAIN accuracy : 0.14050493962678376\n",
      "EVAL \t0.055950164794921875 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 11.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 11.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.19it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 42.26it/s][A\n",
      "\n",
      " 60%|██████    | 9/15 [01:00<00:25,  4.18s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 10.185219168663025\n",
      "TOTAL EVAL LOSS 10.537685453891754\n",
      "TRAIN \t1.341308832168579 secs\n",
      "TRAIN accuracy : 0.14818880351262348\n",
      "EVAL \t0.0484468936920166 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.03it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.11it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 39.89it/s][A\n",
      "\n",
      " 67%|██████▋   | 10/15 [01:02<00:16,  3.34s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 9.340239723523458\n",
      "TOTAL EVAL LOSS 11.479800343513489\n",
      "TRAIN \t1.322998046875 secs\n",
      "TRAIN accuracy : 0.14928649835345773\n",
      "EVAL \t0.05121493339538574 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "Epoch n10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.61it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.33it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.48it/s][A\n",
      "\n",
      " 73%|███████▎  | 11/15 [01:03<00:11,  2.76s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 8.567564169565836\n",
      "TOTAL EVAL LOSS 10.339932441711426\n",
      "TRAIN \t1.3253214359283447 secs\n",
      "TRAIN accuracy : 0.14928649835345773\n",
      "EVAL \t0.04922914505004883 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 11.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 11.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 11.68it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.14it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.48it/s][A\n",
      "\n",
      " 80%|████████  | 12/15 [01:04<00:07,  2.36s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 7.967341363430023\n",
      "TOTAL EVAL LOSS 9.12353128194809\n",
      "TRAIN \t1.3476190567016602 secs\n",
      "TRAIN accuracy : 0.14928649835345773\n",
      "EVAL \t0.0492558479309082 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.66it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00, 10.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 11.20it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 42.32it/s][A\n",
      "\n",
      " 87%|████████▋ | 13/15 [01:06<00:04,  2.06s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 6.618424663941066\n",
      "TOTAL EVAL LOSS 5.60657262802124\n",
      "TRAIN \t1.2903800010681152 secs\n",
      "TRAIN accuracy : 0.14928649835345773\n",
      "EVAL \t0.048297882080078125 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.25it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.59it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.24it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.83it/s][A\n",
      "\n",
      " 93%|█████████▎| 14/15 [01:07<00:01,  1.86s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 5.636082788308461\n",
      "TOTAL EVAL LOSS 5.688945055007935\n",
      "TRAIN \t1.323498010635376 secs\n",
      "TRAIN accuracy : 0.14928649835345773\n",
      "EVAL \t0.05018901824951172 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "Epoch n14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.32it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 12.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.26it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.56it/s][A\n",
      "\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.60s/it]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 4.242877508203189\n",
      "TOTAL EVAL LOSS 2.43842214345932\n",
      "TRAIN \t1.3327527046203613 secs\n",
      "TRAIN accuracy : 0.14928649835345773\n",
      "EVAL \t0.050402164459228516 secs\n",
      "EVAL accuracy : 0.14799154334038056\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:09<04:36, 69.19s/it]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment 2\n",
      "Epoch n0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:03,  3.22s/it]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:06,  3.15s/it]\u001B[A\u001B[A\n",
      "\n",
      "3it [00:09,  3.16s/it]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:12,  3.22s/it]\u001B[A\u001B[A\n",
      "\n",
      "5it [00:16,  3.26s/it]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:19,  3.29s/it]\u001B[A\u001B[A\n",
      "\n",
      "7it [00:22,  3.32s/it]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:26,  3.33s/it]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:29,  3.36s/it]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:32,  3.34s/it]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:36,  3.35s/it]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:39,  3.36s/it]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:43,  3.37s/it]\u001B[A\u001B[A\n",
      "\n",
      "14it [00:46,  3.43s/it]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:50,  3.35s/it]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 46.36526425679525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:01,  1.99s/it]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:04,  2.04s/it]\u001B[A\u001B[A\n",
      "\n",
      "  7%|▋         | 1/15 [00:54<12:41, 54.37s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:00, 12.66it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL EVAL LOSS 43.85599613189697\n",
      "TRAIN \t50.26697897911072 secs\n",
      "TRAIN accuracy : 0.0\n",
      "EVAL \t4.077505111694336 secs\n",
      "EVAL accuracy : 0.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4it [00:00, 13.15it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.34it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.75it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.64it/s][A\n",
      "\n",
      " 13%|█▎        | 2/15 [00:55<08:19, 38.46s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 42.08894077936808\n",
      "TOTAL EVAL LOSS 38.99579167366028\n",
      "TRAIN \t1.2626397609710693 secs\n",
      "TRAIN accuracy : 0.0025380710659898475\n",
      "EVAL \t0.049105167388916016 secs\n",
      "EVAL accuracy : 0.0\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 14.31it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 14.39it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 42.36it/s][A\n",
      "\n",
      " 20%|██        | 3/15 [00:57<05:27, 27.32s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 38.31567653020223\n",
      "TOTAL EVAL LOSS 36.16797208786011\n",
      "TRAIN \t1.2682240009307861 secs\n",
      "TRAIN accuracy : 0.04568527918781726\n",
      "EVAL \t0.04828691482543945 secs\n",
      "EVAL accuracy : 0.07846715328467153\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 13.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.93it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.35it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.37it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.49it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.35it/s][A\n",
      "\n",
      " 27%|██▋       | 4/15 [00:58<03:34, 19.53s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 33.809810956319176\n",
      "TOTAL EVAL LOSS 31.87320828437805\n",
      "TRAIN \t1.2861509323120117 secs\n",
      "TRAIN accuracy : 0.1065989847715736\n",
      "EVAL \t0.04954075813293457 secs\n",
      "EVAL accuracy : 0.10218978102189781\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 14.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.22it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00, 10.04it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.64it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.30it/s][A\n",
      "\n",
      " 33%|███▎      | 5/15 [00:59<02:20, 14.08s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 29.34308910369873\n",
      "TOTAL EVAL LOSS 26.523622274398804\n",
      "TRAIN \t1.291384220123291 secs\n",
      "TRAIN accuracy : 0.12436548223350254\n",
      "EVAL \t0.05072474479675293 secs\n",
      "EVAL accuracy : 0.10583941605839416\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 13.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.27it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.76it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:00,  8.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:01,  8.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:01,  9.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.78it/s][A\n",
      "\n",
      " 40%|████      | 6/15 [01:01<01:32, 10.27s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 24.484535773595173\n",
      "TOTAL EVAL LOSS 21.080610752105713\n",
      "TRAIN \t1.3192150592803955 secs\n",
      "TRAIN accuracy : 0.1218274111675127\n",
      "EVAL \t0.05020880699157715 secs\n",
      "EVAL accuracy : 0.10401459854014598\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.73it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.16it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.88it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.94it/s]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:00,  7.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:01,  8.92it/s]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:01,  9.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.50it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 38.46it/s][A\n",
      "\n",
      " 47%|████▋     | 7/15 [01:02<01:00,  7.60s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 18.532419204711914\n",
      "TOTAL EVAL LOSS 16.128525733947754\n",
      "TRAIN \t1.3049101829528809 secs\n",
      "TRAIN accuracy : 0.09644670050761421\n",
      "EVAL \t0.05304694175720215 secs\n",
      "EVAL accuracy : 0.11313868613138686\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 13.41it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.36it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.87it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:00,  7.81it/s]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:01,  8.69it/s]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:01,  9.62it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.12it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 34.34it/s][A\n",
      "\n",
      " 53%|█████▎    | 8/15 [01:03<00:40,  5.75s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 14.354999780654907\n",
      "TOTAL EVAL LOSS 13.331412672996521\n",
      "TRAIN \t1.3497388362884521 secs\n",
      "TRAIN accuracy : 0.1116751269035533\n",
      "EVAL \t0.05942821502685547 secs\n",
      "EVAL accuracy : 0.10401459854014598\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 12.86it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 12.72it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 12.95it/s]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:00,  7.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:01,  8.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:01,  9.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.44it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.90it/s][A\n",
      "\n",
      " 60%|██████    | 9/15 [01:05<00:26,  4.44s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 11.489587704340616\n",
      "TOTAL EVAL LOSS 9.500527679920197\n",
      "TRAIN \t1.312593936920166 secs\n",
      "TRAIN accuracy : 0.1319796954314721\n",
      "EVAL \t0.04997897148132324 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 13.71it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.91it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.42it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00, 10.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 40.78it/s][A\n",
      "\n",
      " 67%|██████▋   | 10/15 [01:06<00:17,  3.50s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 9.785056789716085\n",
      "TOTAL EVAL LOSS 9.681882858276367\n",
      "TRAIN \t1.2620820999145508 secs\n",
      "TRAIN accuracy : 0.14974619289340102\n",
      "EVAL \t0.05013084411621094 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "Epoch n10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 13.80it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 13.98it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.96it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.65it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.83it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 39.38it/s][A\n",
      "\n",
      " 73%|███████▎  | 11/15 [01:07<00:11,  2.85s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 8.597739319006601\n",
      "TOTAL EVAL LOSS 8.569563031196594\n",
      "TRAIN \t1.269345998764038 secs\n",
      "TRAIN accuracy : 0.14974619289340102\n",
      "EVAL \t0.05184793472290039 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 14.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 14.18it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.57it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.89it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.67it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.33it/s][A\n",
      "\n",
      " 80%|████████  | 12/15 [01:09<00:07,  2.40s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 7.4720691839853925\n",
      "TOTAL EVAL LOSS 5.415187478065491\n",
      "TRAIN \t1.2783539295196533 secs\n",
      "TRAIN accuracy : 0.14974619289340102\n",
      "EVAL \t0.0494999885559082 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 14.07it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 14.30it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.79it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00, 10.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.70it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.90it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 41.60it/s][A\n",
      "\n",
      " 87%|████████▋ | 13/15 [01:10<00:04,  2.08s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 6.153044561545054\n",
      "TOTAL EVAL LOSS 5.51902174949646\n",
      "TRAIN \t1.2613489627838135 secs\n",
      "TRAIN accuracy : 0.14974619289340102\n",
      "EVAL \t0.049250125885009766 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "Epoch n13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 13.99it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 14.09it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.10it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.45it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.85it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.38it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.43it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 42.52it/s][A\n",
      "\n",
      " 93%|█████████▎| 14/15 [01:12<00:01,  1.87s/it]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 4.9165984988212585\n",
      "TOTAL EVAL LOSS 2.907649278640747\n",
      "TRAIN \t1.3139839172363281 secs\n",
      "TRAIN accuracy : 0.14974619289340102\n",
      "EVAL \t0.048120975494384766 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n",
      "Epoch n14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2it [00:00, 14.01it/s]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:00, 14.05it/s]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:00, 13.48it/s]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:00, 13.54it/s]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:00,  9.97it/s]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:01, 10.74it/s]\u001B[A\u001B[A\n",
      "\n",
      "15it [00:01, 11.84it/s]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "2it [00:00, 42.35it/s][A\n",
      "\n",
      "100%|██████████| 15/15 [01:13<00:00,  4.89s/it]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN LOSS 2.5542798191308975\n",
      "TOTAL EVAL LOSS 0.6677091866731644\n",
      "TRAIN \t1.2681808471679688 secs\n",
      "TRAIN accuracy : 0.14974619289340102\n",
      "EVAL \t0.04832792282104492 secs\n",
      "EVAL accuracy : 0.14963503649635038\n",
      "\n",
      "\n",
      "** ** * Saving fine - tuned model ** ** * \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:22<03:31, 70.48s/it]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001B[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Experiment 3\n",
      "Epoch n0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:03,  3.56s/it]\u001B[A\u001B[A\n",
      "\n",
      "2it [00:07,  3.57s/it]\u001B[A\u001B[A\n",
      "\n",
      "3it [00:08,  2.89s/it]\u001B[A\u001B[A\n",
      "\n",
      "4it [00:12,  3.13s/it]\u001B[A\u001B[A\n",
      "\n",
      "5it [00:15,  3.29s/it]\u001B[A\u001B[A\n",
      "\n",
      "6it [00:19,  3.39s/it]\u001B[A\u001B[A\n",
      "\n",
      "7it [00:22,  3.41s/it]\u001B[A\u001B[A\n",
      "\n",
      "8it [00:26,  3.51s/it]\u001B[A\u001B[A\n",
      "\n",
      "9it [00:30,  3.60s/it]\u001B[A\u001B[A\n",
      "\n",
      "10it [00:34,  3.68s/it]\u001B[A\u001B[A\n",
      "\n",
      "11it [00:38,  3.72s/it]\u001B[A\u001B[A\n",
      "\n",
      "12it [00:41,  3.76s/it]\u001B[A\u001B[A\n",
      "\n",
      "13it [00:47,  3.68s/it]\u001B[A\u001B[A\n",
      "  0%|          | 0/15 [00:47<?, ?it/s]\n",
      " 40%|████      | 2/5 [03:10<04:45, 95.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mexperiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_experiments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[21], line 19\u001B[0m, in \u001B[0;36mexperiment\u001B[0;34m(num_experiments)\u001B[0m\n\u001B[1;32m     16\u001B[0m trainload \u001B[38;5;241m=\u001B[39m GraphLoader(GDSet(trainDSet), batch_size\u001B[38;5;241m=\u001B[39mtrain_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m], shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     17\u001B[0m valload \u001B[38;5;241m=\u001B[39m GraphLoader(GDSet(valDSet), batch_size\u001B[38;5;241m=\u001B[39mtrain_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m], shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 19\u001B[0m train_loss, val_loss, accuracy_train, accuracy_eval, train_time_cost, val_time_cost \u001B[38;5;241m=\u001B[39m \u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptim_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdevice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m df\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mlen\u001B[39m(df)] \u001B[38;5;241m=\u001B[39m [exp \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGT_BERT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVal Accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, accuracy_eval]\n\u001B[1;32m     24\u001B[0m df\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mlen\u001B[39m(df)] \u001B[38;5;241m=\u001B[39m [exp \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGT_BERT\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain Loss\u001B[39m\u001B[38;5;124m'\u001B[39m, train_loss]\n",
      "Cell \u001B[0;32mIn[20], line 8\u001B[0m, in \u001B[0;36mrun_epoch\u001B[0;34m(model, optim_model, trainload, valload, device, exp, writer)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(train_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m])):\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch n\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e))\n\u001B[0;32m----> 8\u001B[0m     train_loss, train_time_cost, pred_train, ytrue_train \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptim_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     val_loss, val_time_cost, pred_eval, ytrue_eval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(model, valload, device, writer, e)\n\u001B[1;32m     10\u001B[0m     accuracy_train \u001B[38;5;241m=\u001B[39m skm\u001B[38;5;241m.\u001B[39maccuracy_score(ytrue_train\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy(), pred_train\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "Cell \u001B[0;32mIn[18], line 31\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, optim, trainload, device, writer, epoch)\u001B[0m\n\u001B[1;32m     28\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m graph_batch\u001B[38;5;241m.\u001B[39medge_attr\n\u001B[1;32m     29\u001B[0m batch \u001B[38;5;241m=\u001B[39m graph_batch\u001B[38;5;241m.\u001B[39mbatch\n\u001B[0;32m---> 31\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index_readout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m loss \u001B[38;5;241m=\u001B[39m CE_loss(pred, labels_nodes)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# Update TensorBoard for train loss per iteration\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[9], line 11\u001B[0m, in \u001B[0;36mPre_training_1.forward\u001B[0;34m(self, nodes, edge_index, edge_index_readout, edge_attr, batch)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, nodes, edge_index, edge_index_readout, edge_attr, batch):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Define the forward pass using self.gnn and self.linear as needed\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m     vst,x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index_readout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(x)\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[7], line 20\u001B[0m, in \u001B[0;36mGraphTransformer.forward\u001B[0;34m(self, x, edge_index, edge_index_readout, edge_attr, batch)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_index_readout, edge_attr, batch):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m#print(\"GT\")\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     indices \u001B[38;5;241m=\u001B[39m (x\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mnonzero()\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[0;32m---> 20\u001B[0m     h_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformerconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_ee\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     h_nodes \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mGELU()(h_nodes)\n\u001B[1;32m     22\u001B[0m     h_nodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformerconv2(x\u001B[38;5;241m=\u001B[39mh_nodes, edge_index\u001B[38;5;241m=\u001B[39medge_index, edge_attr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_ee(edge_attr), batch\u001B[38;5;241m=\u001B[39mbatch)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[6], line 99\u001B[0m, in \u001B[0;36mTransformerConv.forward\u001B[0;34m(self, x, edge_index, edge_attr, batch, return_attention_weights)\u001B[0m\n\u001B[1;32m     96\u001B[0m residual \u001B[38;5;241m=\u001B[39m out\n\u001B[1;32m     98\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayernorm2(out)\n\u001B[0;32m---> 99\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mffn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    100\u001B[0m out \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(out, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m    101\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn2(out)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.5/envs/projet_AMAL/lib/python3.11/site-packages/torch_geometric/nn/dense/linear.py:130\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    126\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m        x (torch.Tensor): The input features.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "df = experiment(num_experiments=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T11:24:09.621082Z",
     "start_time": "2024-01-21T11:20:58.744758Z"
    }
   },
   "id": "36a55170938c7bf8",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    Experiment    Model        Metric      Score\n0            1  GT_BERT  Val Accuracy   0.147826\n1            1  GT_BERT    Train Loss   0.000004\n2            1  GT_BERT      Val Loss   0.000000\n3            1  GT_BERT    Train Time  76.409270\n4            1  GT_BERT      Val Time   3.805819\n5            2  GT_BERT  Val Accuracy   0.150000\n6            2  GT_BERT    Train Loss   0.000001\n7            2  GT_BERT      Val Loss   0.000000\n8            2  GT_BERT    Train Time  75.925956\n9            2  GT_BERT      Val Time   4.217366\n10           3  GT_BERT  Val Accuracy   0.147887\n11           3  GT_BERT    Train Loss   0.000002\n12           3  GT_BERT      Val Loss   0.000000\n13           3  GT_BERT    Train Time  73.605045\n14           3  GT_BERT      Val Time   4.199621\n15           4  GT_BERT  Val Accuracy   0.147059\n16           4  GT_BERT    Train Loss   0.000002\n17           4  GT_BERT      Val Loss   0.000000\n18           4  GT_BERT    Train Time  80.288804\n19           4  GT_BERT      Val Time   4.489087\n20           5  GT_BERT  Val Accuracy   0.148472\n21           5  GT_BERT    Train Loss   0.000001\n22           5  GT_BERT      Val Loss   0.000000\n23           5  GT_BERT    Train Time  85.481094\n24           5  GT_BERT      Val Time   5.057503",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Experiment</th>\n      <th>Model</th>\n      <th>Metric</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>GT_BERT</td>\n      <td>Val Accuracy</td>\n      <td>0.147826</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>GT_BERT</td>\n      <td>Train Loss</td>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>GT_BERT</td>\n      <td>Val Loss</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>GT_BERT</td>\n      <td>Train Time</td>\n      <td>76.409270</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>GT_BERT</td>\n      <td>Val Time</td>\n      <td>3.805819</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>GT_BERT</td>\n      <td>Val Accuracy</td>\n      <td>0.150000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>GT_BERT</td>\n      <td>Train Loss</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>GT_BERT</td>\n      <td>Val Loss</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>GT_BERT</td>\n      <td>Train Time</td>\n      <td>75.925956</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>GT_BERT</td>\n      <td>Val Time</td>\n      <td>4.217366</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>GT_BERT</td>\n      <td>Val Accuracy</td>\n      <td>0.147887</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>GT_BERT</td>\n      <td>Train Loss</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3</td>\n      <td>GT_BERT</td>\n      <td>Val Loss</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3</td>\n      <td>GT_BERT</td>\n      <td>Train Time</td>\n      <td>73.605045</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3</td>\n      <td>GT_BERT</td>\n      <td>Val Time</td>\n      <td>4.199621</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4</td>\n      <td>GT_BERT</td>\n      <td>Val Accuracy</td>\n      <td>0.147059</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>4</td>\n      <td>GT_BERT</td>\n      <td>Train Loss</td>\n      <td>0.000002</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>4</td>\n      <td>GT_BERT</td>\n      <td>Val Loss</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>4</td>\n      <td>GT_BERT</td>\n      <td>Train Time</td>\n      <td>80.288804</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4</td>\n      <td>GT_BERT</td>\n      <td>Val Time</td>\n      <td>4.489087</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5</td>\n      <td>GT_BERT</td>\n      <td>Val Accuracy</td>\n      <td>0.148472</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>5</td>\n      <td>GT_BERT</td>\n      <td>Train Loss</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>5</td>\n      <td>GT_BERT</td>\n      <td>Val Loss</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>5</td>\n      <td>GT_BERT</td>\n      <td>Train Time</td>\n      <td>85.481094</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>5</td>\n      <td>GT_BERT</td>\n      <td>Val Time</td>\n      <td>5.057503</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T14:03:19.796523Z",
     "start_time": "2024-01-20T14:03:19.508815Z"
    }
   },
   "id": "4edbf283ecdebead",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Group by Model and Metric and calculate average and standard deviation\n",
    "result_df = df.groupby(['Model', 'Metric']).agg({'Score': ['mean', 'std']}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "result_df.columns = ['Model', 'Metric', 'Average Score', 'Standard Deviation']\n",
    "\n",
    "result_df['Average Score'] = result_df['Average Score'].round(2)\n",
    "result_df['Standard Deviation'] = result_df['Standard Deviation'].round(2)\n",
    "\n",
    "# save the result\n",
    "result_df.to_csv(path_results + 'dataframes/' + 'GT_behrt_results_pretraining_1_global.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T14:03:19.827367Z",
     "start_time": "2024-01-20T14:03:19.517073Z"
    }
   },
   "id": "d224df88f97d04a3",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     Model        Metric  Average Score  Standard Deviation\n0  GT_BERT    Train Loss           0.00                0.00\n1  GT_BERT    Train Time          78.34                4.66\n2  GT_BERT  Val Accuracy           0.15                0.00\n3  GT_BERT      Val Loss           0.00                0.00\n4  GT_BERT      Val Time           4.35                0.46",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Metric</th>\n      <th>Average Score</th>\n      <th>Standard Deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GT_BERT</td>\n      <td>Train Loss</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GT_BERT</td>\n      <td>Train Time</td>\n      <td>78.34</td>\n      <td>4.66</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GT_BERT</td>\n      <td>Val Accuracy</td>\n      <td>0.15</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GT_BERT</td>\n      <td>Val Loss</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GT_BERT</td>\n      <td>Val Time</td>\n      <td>4.35</td>\n      <td>0.46</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # print results\n",
    "result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T14:03:19.834919Z",
     "start_time": "2024-01-20T14:03:19.522791Z"
    }
   },
   "id": "1af64f654cc95d4f",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T14:03:19.837251Z",
     "start_time": "2024-01-20T14:03:19.523045Z"
    }
   },
   "id": "4c1248084784f05f",
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
